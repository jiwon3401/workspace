{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045b52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from glob import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "#from torch_poly_lr_decay import PolynomialLRDecay\n",
    "import random\n",
    "from torchvision import models\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import math\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a937b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb  3 22:16:08 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:19:00.0 Off |                  N/A |\n",
      "|  0%   28C    P8    24W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:1A:00.0 Off |                  N/A |\n",
      "|  0%   28C    P8    21W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 3090    Off  | 00000000:67:00.0 Off |                  N/A |\n",
      "|  0%   40C    P2   214W / 350W |   7254MiB / 24268MiB |     72%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 3090    Off  | 00000000:68:00.0 Off |                  N/A |\n",
      "|  0%   34C    P2   164W / 350W |   3332MiB / 24265MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1268      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1268      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1268      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A     25089      C   python3                          7246MiB |\n",
      "|    3   N/A  N/A      1268      G   /usr/lib/xorg/Xorg                 16MiB |\n",
      "|    3   N/A  N/A     25089      C   python3                          3311MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b755e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "torch.set_num_threads(8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7b2a4-cfc3-470f-a644-dfcb86c75a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_in = \"./datasets/train/africa\"\n",
    "# file_list = os.listdir(dir_in)\n",
    "# for file in file_list:\n",
    "#     if file.endswith(\".wav\"):\n",
    "#         print(file)\n",
    "#africa_ex1 = glob('dataset/train/africa/*.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf02c8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41ab8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_ex1 = 'common_voice.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00761c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
    "    wav,sr = librosa.load(file_path,sr=sr)\n",
    "    if wav.shape[0]<5*sr:\n",
    "        wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "        \n",
    "    else:\n",
    "        wav=wav[:5*sr]\n",
    "    spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft, hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "    spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "    \n",
    "    return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "838a85bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-45.021706, -45.021706, -45.021706, ..., -28.46846 , -33.066696,\n",
       "        -28.08957 ],\n",
       "       [-45.021706, -45.021706, -45.021706, ..., -33.386353, -31.23667 ,\n",
       "        -26.057806],\n",
       "       [-45.021706, -45.021706, -45.021706, ..., -17.478779, -13.195372,\n",
       "        -14.487791],\n",
       "       ...,\n",
       "       [-45.021706, -45.021706, -45.021706, ..., -45.021706, -45.021706,\n",
       "        -45.021706],\n",
       "       [-45.021706, -45.021706, -45.021706, ..., -45.021706, -45.021706,\n",
       "        -45.021706],\n",
       "       [-45.021706, -45.021706, -45.021706, ..., -45.021706, -45.021706,\n",
       "        -45.021706]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_melspectrogram_db(africa_ex1, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76e8e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1, sr1 = librosa.load(africa_ex1, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "45dbfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115584"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "831a3ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[:5*16000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5f2508eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 1.09342108e-13, ...,\n",
       "        3.92185996e-07, 1.39143395e-07, 3.39177888e-07],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.09157238e-13, ...,\n",
       "        9.95654887e-07, 1.94803462e-07, 8.49502499e-07],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.08851005e-13, ...,\n",
       "        1.34179049e-06, 1.75701445e-07, 1.12314069e-06],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.49644865e-14, ...,\n",
       "        8.29698266e-09, 9.12768083e-09, 3.21373572e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.43796746e-14, ...,\n",
       "        2.39989895e-09, 3.32916317e-09, 1.76992021e-09],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.99734236e-15, ...,\n",
       "        5.83970441e-11, 1.12407923e-10, 1.88435836e-10]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "africa_ex1 = 'common_voice.wav'\n",
    "data1, sr1 = librosa.load(africa_ex1, sr=16000)\n",
    "mel_africa_wav = librosa.feature.melspectrogram(data1, sr=16000, n_fft=2048, win_length=200, hop_length=160, n_mels=64)\n",
    "mel_africa_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c61b6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa.display\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mel_africa_wav, ref=0.00002), sr=16000, y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e6868cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate(x, audio_length):\n",
    "    \"\"\"Pad all audio to specific length.\"\"\"\n",
    "    length = len(x)\n",
    "    if length <= audio_length:\n",
    "        return np.concatenate((x, np.zeros(audio_length - length)), axis=0), length\n",
    "    else:\n",
    "        return x[:audio_length], audio_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0cba4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d264fa8",
   "metadata": {},
   "source": [
    "### path 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0f7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_train = sorted(glob(\"./datasets/train/africa/*.wav\"))\n",
    "australia_train = sorted(glob(\"./datasets/train/australia/*.wav\"))\n",
    "canada_train = sorted(glob(\"./datasets/train/canada/*.wav\"))\n",
    "england_train = sorted(glob(\"./datasets/train/england/*.wav\"))\n",
    "hongkong_train = sorted(glob(\"./datasets/train/hongkong/*.wav\"))\n",
    "us_train = sorted(glob(\"./datasets/train/us/*.wav\"))\n",
    "\n",
    "sample_submission = pd.read_csv(\"./datasets/sample_submission.csv\")\n",
    "#test_paths = [f'./datasets/test/{k}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb8d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = glob(\"./datasets/test/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc399edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        data, sr = librosa.load(path, sr=16000)\n",
    "        result.append(data)\n",
    "    result = np.array(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc4005a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2500/2500 [05:05<00:00,  8.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1000/1000 [02:02<00:00,  8.14it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1000/1000 [01:56<00:00,  8.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10000/10000 [19:09<00:00,  8.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 1020/1020 [02:23<00:00,  7.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10000/10000 [18:50<00:00,  8.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# africa_train_data = load_data(africa_train)\n",
    "# np.save(\"./datasets/aftrica-sorted.npy\", africa_train_data)\n",
    "\n",
    "# australia_train_data = load_data(australia_train)\n",
    "# np.save(\"./datasets/australia-sorted.npy\", australia_train_data)\n",
    "\n",
    "# canada_train_data = load_data(canada_train)\n",
    "# np.save(\"./datasets/canada-sorted.npy\", canada_train_data)\n",
    "\n",
    "# england_train_data = load_data(england_train)\n",
    "# np.save(\"./datasets/england-sorted.npy\", england_train_data)\n",
    "\n",
    "# hongkong_train_data = load_data(hongkong_train)\n",
    "# np.save(\"./datasets/hongkong-sorted.npy\", hongkong_train_data)\n",
    "\n",
    "# us_train_data = load_data(us_train)\n",
    "# np.save(\"./datasets/us-sorted.npy\", us_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46fd0add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 6100/6100 [13:22<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_data = load_data(test_path) #6100개\n",
    "# np.save(\"./datasets/test_npy.npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5de1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_train_data = np.load(\"./datasets/africa-sorted.npy\", allow_pickle = True)\n",
    "australia_train_data = np.load(\"./datasets/australia-sorted.npy\", allow_pickle = True)\n",
    "canada_train_data = np.load(\"./datasets/canada-sorted.npy\", allow_pickle = True)\n",
    "england_train_data = np.load(\"./datasets/england-sorted.npy\", allow_pickle = True)\n",
    "hongkong_train_data = np.load(\"./datasets/hongkong-sorted.npy\", allow_pickle = True)\n",
    "us_train_data = np.load(\"./datasets/us-sorted.npy\", allow_pickle = True)\n",
    "train_data_list = [africa_train_data, australia_train_data, canada_train_data, england_train_data, hongkong_train_data, us_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc7d3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.concatenate(train_data_list ,axis=0)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd9f44f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2b489",
   "metadata": {},
   "source": [
    "feature 자르기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa116f",
   "metadata": {},
   "source": [
    "`wav\n",
    "  sr: 32000 \n",
    "  window_size: 1024\n",
    "  hop_length: 320\n",
    "  mel_bins: 64\n",
    "  `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63ce45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(data, sr=16000, n_fft=2048, win_length=200, hop_length=160, n_mels=64):\n",
    "    \n",
    "    mel = []\n",
    "    for i in tqdm(data):\n",
    "        mel_ = librosa.feature.melspectrogram(i, sr=sr, n_fft=n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "        mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    #정규화를 여기서 해줘도 되고 , 뒤에서 데이터 다 만든후에 해줘도됨.\n",
    "    \n",
    "#     mel_mean = mel.mean()\n",
    "#     mel = (mel - mel_mean)\n",
    "    \n",
    "    return mel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86156d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_length(data, d_mini):\n",
    "    result = []\n",
    "    for value in tqdm(data):\n",
    "        value = value[:d_mini]\n",
    "        if len(value) < d_mini:\n",
    "            value = np.append(value, [0]*(d_mini-len(value))) #kinda padding\n",
    "        result.append(value)\n",
    "    result = np.array(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005dafd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        1.3940811e-06, -1.0920638e-06,  1.0484886e-06], dtype=float32),\n",
       "       array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "       -1.4028327e-05, -1.0613157e-05, -1.7424460e-05], dtype=float32),\n",
       "       array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), ...,\n",
       "       array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       "       array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "       -2.5764151e-05,  1.5654117e-05,  2.3484859e-05], dtype=float32),\n",
       "       array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        7.1461989e-05, -3.5540674e-05,  1.9304553e-05], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2677d877",
   "metadata": {},
   "source": [
    "`win_length` : 음성을 작은 조각으로 자를때 작은 조각의 크기.   \n",
    "`hop_length` : 음성을 작은 조각으로 자를때 자르는 간격  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753a1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25520/25520 [00:12<00:00, 1995.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x = set_length(train_x, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831140dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 100000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f953f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25520/25520 [04:42<00:00, 90.22it/s]\n",
      "100%|██████████| 25520/25520 [04:37<00:00, 92.09it/s]\n",
      "100%|██████████| 25520/25520 [04:39<00:00, 91.37it/s]\n",
      "100%|██████████| 25520/25520 [04:44<00:00, 89.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# #train_x = np.concatenate(train_data_list ,axis=0)\n",
    "# train_x_200 = get_feature(data = train_x, win_length=200)\n",
    "# train_x_400 = get_feature(data = train_x, win_length=400)\n",
    "# train_x_800 = get_feature(data = train_x, win_length=800)\n",
    "# train_x_1000 = get_feature(data = train_x, win_length=1000)\n",
    "\n",
    "# train_x_200 = train_x_200.reshape(train_x_200.shape[0], train_x_200.shape[1], train_x_200.shape[2], 1)\n",
    "# train_x_400 = train_x_400.reshape(train_x_400.shape[0], train_x_400.shape[1], train_x_400.shape[2], 1)\n",
    "# train_x_800 = train_x_800.reshape(train_x_800.shape[0], train_x_800.shape[1], train_x_800.shape[2], 1)\n",
    "# train_x_1000 = train_x_1000.reshape(train_x_1000.shape[0], train_x_1000.shape[1], train_x_1000.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abaed426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 64, 626, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_200.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d5d429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reshape_list = [train_x_200, train_x_400, train_x_800, train_x_1000]\n",
    "train_x_multi = np.concatenate(train_reshape_list, -1)\n",
    "np.save('./datasets/train_x_multi.npy', train_x_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "278117e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-51.2156948 ],\n",
       "          [-51.29318657],\n",
       "          [-36.53980915]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-39.61816699],\n",
       "          [-39.18733141],\n",
       "          [-35.00829857]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-32.3531565 ],\n",
       "          [-32.59215093],\n",
       "          [-33.75060227]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-64.15609322],\n",
       "          [-70.52419645],\n",
       "          [-56.33333863]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-71.3021972 ],\n",
       "          [-78.62044915],\n",
       "          [-56.8433992 ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-57.01043746]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-60.4488139 ],\n",
       "          [-65.72332103],\n",
       "          [-64.6771296 ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-55.84274181],\n",
       "          [-59.71711592],\n",
       "          [-64.40136039]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-54.80200156],\n",
       "          [-57.38382464],\n",
       "          [-64.67925362]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]]]),\n",
       " array([[[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-53.43557989],\n",
       "          [-59.39863386],\n",
       "          [-40.38029213]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-48.50145947],\n",
       "          [-49.67928106],\n",
       "          [-37.20840452]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-33.91014068],\n",
       "          [-33.6960545 ],\n",
       "          [-32.73995217]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-64.19949932],\n",
       "          [-68.81574239],\n",
       "          [-58.72854494]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-71.68775285],\n",
       "          [-75.53276065],\n",
       "          [-59.3073228 ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-79.59782706],\n",
       "          [-59.46569237]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-68.1853602 ],\n",
       "          [-76.7059114 ],\n",
       "          [-67.32750391]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-55.51722631],\n",
       "          [-61.11012238],\n",
       "          [-62.40306294]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-51.82919643],\n",
       "          [-54.82996764],\n",
       "          [-61.22087481]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]]]),\n",
       " array([[[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-57.91553972],\n",
       "          [-48.05005672],\n",
       "          [-44.70392951]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-49.68404791],\n",
       "          [-44.2587192 ],\n",
       "          [-41.70609891]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-39.98688909],\n",
       "          [-36.72089311],\n",
       "          [-35.92380165]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-65.8948315 ],\n",
       "          [-64.43052719],\n",
       "          [-62.48747729]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-72.27868197],\n",
       "          [-66.45750433],\n",
       "          [-63.19847277]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-67.02712074],\n",
       "          [-63.37508386]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-75.6113661 ],\n",
       "          [-72.60393206],\n",
       "          [-71.90577044]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-57.76568484],\n",
       "          [-62.95369487],\n",
       "          [-64.92534256]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-50.01465537],\n",
       "          [-54.4560673 ],\n",
       "          [-59.43204732]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]]]),\n",
       " array([[[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-54.94383172],\n",
       "          [-47.93112826],\n",
       "          [-45.88780145]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-48.35948799],\n",
       "          [-44.26665597],\n",
       "          [-42.81084584]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-41.33288531],\n",
       "          [-37.76337733],\n",
       "          [-37.09182627]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-65.89897817],\n",
       "          [-64.28080889],\n",
       "          [-63.46378037]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-70.86886376],\n",
       "          [-66.20903769],\n",
       "          [-64.30139325]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-75.27952686],\n",
       "          [-66.78631191],\n",
       "          [-64.51092977]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-75.48771393],\n",
       "          [-73.23545017],\n",
       "          [-72.67059049]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-58.3870107 ],\n",
       "          [-62.51010697],\n",
       "          [-65.81171201]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-49.17285503],\n",
       "          [-53.92065088],\n",
       "          [-58.77973532]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]],\n",
       " \n",
       " \n",
       "        [[[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-79.62347022],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-78.81513592],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]],\n",
       " \n",
       "         [[-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          ...,\n",
       "          [-80.        ],\n",
       "          [-80.        ],\n",
       "          [-80.        ]]]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reshape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4acffa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 64, 626, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35525df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6100/6100 [00:02<00:00, 2741.87it/s]\n",
      "100%|██████████| 6100/6100 [01:06<00:00, 92.29it/s]\n",
      "100%|██████████| 6100/6100 [01:06<00:00, 91.67it/s]\n",
      "100%|██████████| 6100/6100 [01:07<00:00, 90.82it/s]\n",
      "100%|██████████| 6100/6100 [01:06<00:00, 91.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_x = np.load('./datasets/test_npy.npy', allow_pickle=True)\n",
    "\n",
    "# test_x = set_length(test_x, 100000)\n",
    "# test_x_200 = get_feature(data = test_x, win_length=200)\n",
    "# test_x_400 = get_feature(data = test_x, win_length=400)\n",
    "# test_x_800 = get_feature(data = test_x, win_length=800)\n",
    "# test_x_1000 = get_feature(data = test_x, win_length=1000)\n",
    "\n",
    "\n",
    "# test_x_200 = test_x_200.reshape(test_x_200.shape[0], test_x_200.shape[1], test_x_200.shape[2], 1)\n",
    "# test_x_400 = test_x_400.reshape(test_x_400.shape[0], test_x_400.shape[1], test_x_400.shape[2], 1)\n",
    "# test_x_800 = test_x_800.reshape(test_x_800.shape[0], test_x_800.shape[1], test_x_800.shape[2], 1)\n",
    "# test_x_1000 = test_x_1000.reshape(test_x_1000.shape[0], test_x_1000.shape[1], test_x_1000.shape[2], 1)\n",
    "\n",
    "# test_x_reshape = [test_x_200, test_x_400, test_x_800, test_x_1000]\n",
    "# test_x_multi = np.concatenate(test_x_reshape, -1)\n",
    "# np.save('./datasets/test_x_multi.npy', test_x_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5195d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 64, 626, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d212bf9",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a836fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_bn_relu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(conv_bn_relu, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.BN = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.BN(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6114d1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_bn_relu(\n",
       "  (conv): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_bn_relu(in_channels=4, out_channels=16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b227e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super(Network, self).__init__()\n",
    "        self.N = N\n",
    "        self.AveragePooling = nn.AvgPool2d(2)\n",
    "        self.MaxPooling = nn.MaxPool2d(2)\n",
    "        \n",
    "        \n",
    "        self.input_conv = conv_bn_relu(in_channels=4, out_channels=self.N, kernel_size=3)\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            conv_bn_relu(in_channels=self.N*1, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*4, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*4, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*1, kernel_size=3),\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            conv_bn_relu(in_channels=self.N*1, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*4, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*4, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*1, kernel_size=3),\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            conv_bn_relu(in_channels=self.N*1, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*4, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*4, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*1, kernel_size=3),\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            conv_bn_relu(in_channels=self.N*1, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*4, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*4, out_channels=self.N*2, kernel_size=3),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*1, kernel_size=3),\n",
    "        )\n",
    "        \n",
    "        self.pool_block = nn.Sequential(\n",
    "            conv_bn_relu(in_channels=self.N*1, out_channels=self.N*2, kernel_size=3),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.AvgPool2d(2),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*2, kernel_size=3),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.AvgPool2d(2),\n",
    "            conv_bn_relu(in_channels=self.N*2, out_channels=self.N*2, kernel_size=3),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.N*2, out_features=6),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, out=''):\n",
    "        x = self.input_conv(x)\n",
    "        x = self.MaxPooling(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.pool_block(x)\n",
    "        x=self.output(x)\n",
    "        \n",
    "        if out=='sigmoid':\n",
    "            x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc49e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:input_conv.conv.weight\n",
      "param.shape:torch.Size([16, 4, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:input_conv.conv.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:input_conv.BN.weight\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:input_conv.BN.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.0.conv.weight\n",
      "param.shape:torch.Size([32, 16, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.0.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.0.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.0.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.1.conv.weight\n",
      "param.shape:torch.Size([64, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.1.conv.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.1.BN.weight\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.1.BN.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.2.conv.weight\n",
      "param.shape:torch.Size([32, 64, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.2.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.2.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.2.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.3.conv.weight\n",
      "param.shape:torch.Size([16, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.3.conv.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.3.BN.weight\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block1.3.BN.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.0.conv.weight\n",
      "param.shape:torch.Size([32, 16, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.0.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.0.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.0.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.1.conv.weight\n",
      "param.shape:torch.Size([64, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.1.conv.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.1.BN.weight\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.1.BN.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.2.conv.weight\n",
      "param.shape:torch.Size([32, 64, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.2.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.2.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.2.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.3.conv.weight\n",
      "param.shape:torch.Size([16, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.3.conv.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.3.BN.weight\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block2.3.BN.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.0.conv.weight\n",
      "param.shape:torch.Size([32, 16, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.0.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.0.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.0.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.1.conv.weight\n",
      "param.shape:torch.Size([64, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.1.conv.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.1.BN.weight\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.1.BN.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.2.conv.weight\n",
      "param.shape:torch.Size([32, 64, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.2.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.2.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.2.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.3.conv.weight\n",
      "param.shape:torch.Size([16, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.3.conv.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.3.BN.weight\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block3.3.BN.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.0.conv.weight\n",
      "param.shape:torch.Size([32, 16, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.0.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.0.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.0.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.1.conv.weight\n",
      "param.shape:torch.Size([64, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.1.conv.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.1.BN.weight\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.1.BN.bias\n",
      "param.shape:torch.Size([64])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.2.conv.weight\n",
      "param.shape:torch.Size([32, 64, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.2.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.2.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.2.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.3.conv.weight\n",
      "param.shape:torch.Size([16, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.3.conv.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.3.BN.weight\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:block4.3.BN.bias\n",
      "param.shape:torch.Size([16])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.0.conv.weight\n",
      "param.shape:torch.Size([32, 16, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.0.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.0.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.0.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.3.conv.weight\n",
      "param.shape:torch.Size([32, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.3.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.3.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.3.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.6.conv.weight\n",
      "param.shape:torch.Size([32, 32, 3, 3])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.6.conv.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.6.BN.weight\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:pool_block.6.BN.bias\n",
      "param.shape:torch.Size([32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:output.1.weight\n",
      "param.shape:torch.Size([6, 32])\n",
      "param.requries_grad:True\n",
      "=====================================\n",
      "name:output.1.bias\n",
      "param.shape:torch.Size([6])\n",
      "param.requries_grad:True\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "for name,param in Network(16).named_parameters():\n",
    "    print(f'name:{name}') \n",
    "    print(f'param.shape:{param.shape}') \n",
    "    print(f'param.requries_grad:{param.requires_grad}') \n",
    "    print('=====================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a23b5bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (AveragePooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (MaxPooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (input_conv): conv_bn_relu(\n",
       "    (conv): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (block1): Sequential(\n",
       "    (0): conv_bn_relu(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): conv_bn_relu(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): conv_bn_relu(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): conv_bn_relu(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): conv_bn_relu(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): conv_bn_relu(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): conv_bn_relu(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): conv_bn_relu(\n",
       "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool_block): Sequential(\n",
       "    (0): conv_bn_relu(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Dropout(p=0.15, inplace=False)\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Dropout(p=0.15, inplace=False)\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): conv_bn_relu(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): Dropout(p=0.15, inplace=False)\n",
       "    (8): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Network(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7ac10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting prettytable\n",
      "  Downloading prettytable-3.6.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth in /home/user/anaconda3/lib/python3.8/site-packages (from prettytable) (0.2.5)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0ca45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_conv.conv.weight\n",
      "input_conv.conv.bias\n",
      "input_conv.BN.weight\n",
      "input_conv.BN.bias\n",
      "block1.0.conv.weight\n",
      "block1.0.conv.bias\n",
      "block1.0.BN.weight\n",
      "block1.0.BN.bias\n",
      "block1.1.conv.weight\n",
      "block1.1.conv.bias\n",
      "block1.1.BN.weight\n",
      "block1.1.BN.bias\n",
      "block1.2.conv.weight\n",
      "block1.2.conv.bias\n",
      "block1.2.BN.weight\n",
      "block1.2.BN.bias\n",
      "block1.3.conv.weight\n",
      "block1.3.conv.bias\n",
      "block1.3.BN.weight\n",
      "block1.3.BN.bias\n",
      "block2.0.conv.weight\n",
      "block2.0.conv.bias\n",
      "block2.0.BN.weight\n",
      "block2.0.BN.bias\n",
      "block2.1.conv.weight\n",
      "block2.1.conv.bias\n",
      "block2.1.BN.weight\n",
      "block2.1.BN.bias\n",
      "block2.2.conv.weight\n",
      "block2.2.conv.bias\n",
      "block2.2.BN.weight\n",
      "block2.2.BN.bias\n",
      "block2.3.conv.weight\n",
      "block2.3.conv.bias\n",
      "block2.3.BN.weight\n",
      "block2.3.BN.bias\n",
      "block3.0.conv.weight\n",
      "block3.0.conv.bias\n",
      "block3.0.BN.weight\n",
      "block3.0.BN.bias\n",
      "block3.1.conv.weight\n",
      "block3.1.conv.bias\n",
      "block3.1.BN.weight\n",
      "block3.1.BN.bias\n",
      "block3.2.conv.weight\n",
      "block3.2.conv.bias\n",
      "block3.2.BN.weight\n",
      "block3.2.BN.bias\n",
      "block3.3.conv.weight\n",
      "block3.3.conv.bias\n",
      "block3.3.BN.weight\n",
      "block3.3.BN.bias\n",
      "block4.0.conv.weight\n",
      "block4.0.conv.bias\n",
      "block4.0.BN.weight\n",
      "block4.0.BN.bias\n",
      "block4.1.conv.weight\n",
      "block4.1.conv.bias\n",
      "block4.1.BN.weight\n",
      "block4.1.BN.bias\n",
      "block4.2.conv.weight\n",
      "block4.2.conv.bias\n",
      "block4.2.BN.weight\n",
      "block4.2.BN.bias\n",
      "block4.3.conv.weight\n",
      "block4.3.conv.bias\n",
      "block4.3.BN.weight\n",
      "block4.3.BN.bias\n",
      "pool_block.0.conv.weight\n",
      "pool_block.0.conv.bias\n",
      "pool_block.0.BN.weight\n",
      "pool_block.0.BN.bias\n",
      "pool_block.3.conv.weight\n",
      "pool_block.3.conv.bias\n",
      "pool_block.3.BN.weight\n",
      "pool_block.3.BN.bias\n",
      "pool_block.6.conv.weight\n",
      "pool_block.6.conv.bias\n",
      "pool_block.6.BN.weight\n",
      "pool_block.6.BN.bias\n",
      "output.1.weight\n",
      "output.1.bias\n",
      "+--------------------------+------------+\n",
      "|         Modules          | Parameters |\n",
      "+--------------------------+------------+\n",
      "|  input_conv.conv.weight  |    576     |\n",
      "|   input_conv.conv.bias   |     16     |\n",
      "|   input_conv.BN.weight   |     16     |\n",
      "|    input_conv.BN.bias    |     16     |\n",
      "|   block1.0.conv.weight   |    4608    |\n",
      "|    block1.0.conv.bias    |     32     |\n",
      "|    block1.0.BN.weight    |     32     |\n",
      "|     block1.0.BN.bias     |     32     |\n",
      "|   block1.1.conv.weight   |   18432    |\n",
      "|    block1.1.conv.bias    |     64     |\n",
      "|    block1.1.BN.weight    |     64     |\n",
      "|     block1.1.BN.bias     |     64     |\n",
      "|   block1.2.conv.weight   |   18432    |\n",
      "|    block1.2.conv.bias    |     32     |\n",
      "|    block1.2.BN.weight    |     32     |\n",
      "|     block1.2.BN.bias     |     32     |\n",
      "|   block1.3.conv.weight   |    4608    |\n",
      "|    block1.3.conv.bias    |     16     |\n",
      "|    block1.3.BN.weight    |     16     |\n",
      "|     block1.3.BN.bias     |     16     |\n",
      "|   block2.0.conv.weight   |    4608    |\n",
      "|    block2.0.conv.bias    |     32     |\n",
      "|    block2.0.BN.weight    |     32     |\n",
      "|     block2.0.BN.bias     |     32     |\n",
      "|   block2.1.conv.weight   |   18432    |\n",
      "|    block2.1.conv.bias    |     64     |\n",
      "|    block2.1.BN.weight    |     64     |\n",
      "|     block2.1.BN.bias     |     64     |\n",
      "|   block2.2.conv.weight   |   18432    |\n",
      "|    block2.2.conv.bias    |     32     |\n",
      "|    block2.2.BN.weight    |     32     |\n",
      "|     block2.2.BN.bias     |     32     |\n",
      "|   block2.3.conv.weight   |    4608    |\n",
      "|    block2.3.conv.bias    |     16     |\n",
      "|    block2.3.BN.weight    |     16     |\n",
      "|     block2.3.BN.bias     |     16     |\n",
      "|   block3.0.conv.weight   |    4608    |\n",
      "|    block3.0.conv.bias    |     32     |\n",
      "|    block3.0.BN.weight    |     32     |\n",
      "|     block3.0.BN.bias     |     32     |\n",
      "|   block3.1.conv.weight   |   18432    |\n",
      "|    block3.1.conv.bias    |     64     |\n",
      "|    block3.1.BN.weight    |     64     |\n",
      "|     block3.1.BN.bias     |     64     |\n",
      "|   block3.2.conv.weight   |   18432    |\n",
      "|    block3.2.conv.bias    |     32     |\n",
      "|    block3.2.BN.weight    |     32     |\n",
      "|     block3.2.BN.bias     |     32     |\n",
      "|   block3.3.conv.weight   |    4608    |\n",
      "|    block3.3.conv.bias    |     16     |\n",
      "|    block3.3.BN.weight    |     16     |\n",
      "|     block3.3.BN.bias     |     16     |\n",
      "|   block4.0.conv.weight   |    4608    |\n",
      "|    block4.0.conv.bias    |     32     |\n",
      "|    block4.0.BN.weight    |     32     |\n",
      "|     block4.0.BN.bias     |     32     |\n",
      "|   block4.1.conv.weight   |   18432    |\n",
      "|    block4.1.conv.bias    |     64     |\n",
      "|    block4.1.BN.weight    |     64     |\n",
      "|     block4.1.BN.bias     |     64     |\n",
      "|   block4.2.conv.weight   |   18432    |\n",
      "|    block4.2.conv.bias    |     32     |\n",
      "|    block4.2.BN.weight    |     32     |\n",
      "|     block4.2.BN.bias     |     32     |\n",
      "|   block4.3.conv.weight   |    4608    |\n",
      "|    block4.3.conv.bias    |     16     |\n",
      "|    block4.3.BN.weight    |     16     |\n",
      "|     block4.3.BN.bias     |     16     |\n",
      "| pool_block.0.conv.weight |    4608    |\n",
      "|  pool_block.0.conv.bias  |     32     |\n",
      "|  pool_block.0.BN.weight  |     32     |\n",
      "|   pool_block.0.BN.bias   |     32     |\n",
      "| pool_block.3.conv.weight |    9216    |\n",
      "|  pool_block.3.conv.bias  |     32     |\n",
      "|  pool_block.3.BN.weight  |     32     |\n",
      "|   pool_block.3.BN.bias   |     32     |\n",
      "| pool_block.6.conv.weight |    9216    |\n",
      "|  pool_block.6.conv.bias  |     32     |\n",
      "|  pool_block.6.BN.weight  |     32     |\n",
      "|   pool_block.6.BN.bias   |     32     |\n",
      "|     output.1.weight      |    192     |\n",
      "|      output.1.bias       |     6      |\n",
      "+--------------------------+------------+\n",
      "Total Trainable Params: 210198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210198"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        print(name)\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cccf01e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 16, 16]             592\n",
      "       BatchNorm2d-2           [-1, 16, 16, 16]              32\n",
      "              ReLU-3           [-1, 16, 16, 16]               0\n",
      "      conv_bn_relu-4           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-5             [-1, 16, 8, 8]               0\n",
      "            Conv2d-6             [-1, 32, 8, 8]           4,640\n",
      "       BatchNorm2d-7             [-1, 32, 8, 8]              64\n",
      "              ReLU-8             [-1, 32, 8, 8]               0\n",
      "      conv_bn_relu-9             [-1, 32, 8, 8]               0\n",
      "           Conv2d-10             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
      "             ReLU-12             [-1, 64, 8, 8]               0\n",
      "     conv_bn_relu-13             [-1, 64, 8, 8]               0\n",
      "           Conv2d-14             [-1, 32, 8, 8]          18,464\n",
      "      BatchNorm2d-15             [-1, 32, 8, 8]              64\n",
      "             ReLU-16             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-17             [-1, 32, 8, 8]               0\n",
      "           Conv2d-18             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-19             [-1, 16, 8, 8]              32\n",
      "             ReLU-20             [-1, 16, 8, 8]               0\n",
      "     conv_bn_relu-21             [-1, 16, 8, 8]               0\n",
      "           Conv2d-22             [-1, 32, 8, 8]           4,640\n",
      "      BatchNorm2d-23             [-1, 32, 8, 8]              64\n",
      "             ReLU-24             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-25             [-1, 32, 8, 8]               0\n",
      "           Conv2d-26             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-27             [-1, 64, 8, 8]             128\n",
      "             ReLU-28             [-1, 64, 8, 8]               0\n",
      "     conv_bn_relu-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 32, 8, 8]          18,464\n",
      "      BatchNorm2d-31             [-1, 32, 8, 8]              64\n",
      "             ReLU-32             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-33             [-1, 32, 8, 8]               0\n",
      "           Conv2d-34             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-35             [-1, 16, 8, 8]              32\n",
      "             ReLU-36             [-1, 16, 8, 8]               0\n",
      "     conv_bn_relu-37             [-1, 16, 8, 8]               0\n",
      "           Conv2d-38             [-1, 32, 8, 8]           4,640\n",
      "      BatchNorm2d-39             [-1, 32, 8, 8]              64\n",
      "             ReLU-40             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-41             [-1, 32, 8, 8]               0\n",
      "           Conv2d-42             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
      "             ReLU-44             [-1, 64, 8, 8]               0\n",
      "     conv_bn_relu-45             [-1, 64, 8, 8]               0\n",
      "           Conv2d-46             [-1, 32, 8, 8]          18,464\n",
      "      BatchNorm2d-47             [-1, 32, 8, 8]              64\n",
      "             ReLU-48             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-49             [-1, 32, 8, 8]               0\n",
      "           Conv2d-50             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-51             [-1, 16, 8, 8]              32\n",
      "             ReLU-52             [-1, 16, 8, 8]               0\n",
      "     conv_bn_relu-53             [-1, 16, 8, 8]               0\n",
      "           Conv2d-54             [-1, 32, 8, 8]           4,640\n",
      "      BatchNorm2d-55             [-1, 32, 8, 8]              64\n",
      "             ReLU-56             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-57             [-1, 32, 8, 8]               0\n",
      "           Conv2d-58             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-59             [-1, 64, 8, 8]             128\n",
      "             ReLU-60             [-1, 64, 8, 8]               0\n",
      "     conv_bn_relu-61             [-1, 64, 8, 8]               0\n",
      "           Conv2d-62             [-1, 32, 8, 8]          18,464\n",
      "      BatchNorm2d-63             [-1, 32, 8, 8]              64\n",
      "             ReLU-64             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-65             [-1, 32, 8, 8]               0\n",
      "           Conv2d-66             [-1, 16, 8, 8]           4,624\n",
      "      BatchNorm2d-67             [-1, 16, 8, 8]              32\n",
      "             ReLU-68             [-1, 16, 8, 8]               0\n",
      "     conv_bn_relu-69             [-1, 16, 8, 8]               0\n",
      "           Conv2d-70             [-1, 32, 8, 8]           4,640\n",
      "      BatchNorm2d-71             [-1, 32, 8, 8]              64\n",
      "             ReLU-72             [-1, 32, 8, 8]               0\n",
      "     conv_bn_relu-73             [-1, 32, 8, 8]               0\n",
      "          Dropout-74             [-1, 32, 8, 8]               0\n",
      "        AvgPool2d-75             [-1, 32, 4, 4]               0\n",
      "           Conv2d-76             [-1, 32, 4, 4]           9,248\n",
      "      BatchNorm2d-77             [-1, 32, 4, 4]              64\n",
      "             ReLU-78             [-1, 32, 4, 4]               0\n",
      "     conv_bn_relu-79             [-1, 32, 4, 4]               0\n",
      "          Dropout-80             [-1, 32, 4, 4]               0\n",
      "        AvgPool2d-81             [-1, 32, 2, 2]               0\n",
      "           Conv2d-82             [-1, 32, 2, 2]           9,248\n",
      "      BatchNorm2d-83             [-1, 32, 2, 2]              64\n",
      "             ReLU-84             [-1, 32, 2, 2]               0\n",
      "     conv_bn_relu-85             [-1, 32, 2, 2]               0\n",
      "          Dropout-86             [-1, 32, 2, 2]               0\n",
      "AdaptiveAvgPool2d-87             [-1, 32, 1, 1]               0\n",
      "          Flatten-88                   [-1, 32]               0\n",
      "           Linear-89                    [-1, 6]             198\n",
      "================================================================\n",
      "Total params: 210,198\n",
      "Trainable params: 210,198\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.37\n",
      "Params size (MB): 0.80\n",
      "Estimated Total Size (MB): 2.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Network(16)\n",
    "model.to(device)\n",
    "\n",
    "summary(model, (4,16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d02c31f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520, 100000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fe4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceDatasetSimple(Dataset):\n",
    "        def __init__(self, X, y, transform, inference=False, roll=False):\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.transform = transform\n",
    "            self.inference = inference\n",
    "            self.roll = roll\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            X = self.X[idx]\n",
    "            X = (X-train_x_min)/(train_x_max-train_x_min)\n",
    "            \n",
    "            if self.inference:\n",
    "                X = self.transform(X)\n",
    "                return X\n",
    "            else:\n",
    "                if (self.roll==True) and (random.randint(0, 1)==1):\n",
    "                    X = np.roll(X,random.randint(-200, 200), axis=1)\n",
    "                    \n",
    "                X = self.transform(X)    \n",
    "                y = self.y[idx]\n",
    "                \n",
    "                onehot = np.zeros(6)\n",
    "                onehot[y] = 1.\n",
    "                y = onehot\n",
    "                return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb91cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model, path):\n",
    "    torch.save({'model':model.state_dict()}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc25d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.concatenate((np.zeros(len(africa_train_data), dtype = np.int),\n",
    "                        np.ones(len(australia_train_data), dtype = np.int),\n",
    "                         np.ones(len(canada_train_data), dtype = np.int) * 2,\n",
    "                         np.ones(len(england_train_data), dtype = np.int) * 3,\n",
    "                         np.ones(len(hongkong_train_data), dtype = np.int) * 4,\n",
    "                         np.ones(len(us_train_data), dtype = np.int) * 5), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e83f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./datasets/train_y_sort.npy\", train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c184e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25520,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13797ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.49980     accuracy : 0.38771\n",
      "VALID -> loss : 1.40071     accuracy : 0.40364    best : 1.40071\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.34920     accuracy : 0.43651\n",
      "VALID -> loss : 1.32063     accuracy : 0.43067    best : 1.32063\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.32449     accuracy : 0.45973\n",
      "VALID -> loss : 1.29589     accuracy : 0.48120    best : 1.29589\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.29267     accuracy : 0.48707\n",
      "VALID -> loss : 1.30803     accuracy : 0.46945    best : 1.29589\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27730     accuracy : 0.50808\n",
      "VALID -> loss : 1.27086     accuracy : 0.49177    best : 1.27086\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27775     accuracy : 0.50852\n",
      "VALID -> loss : 1.28820     accuracy : 0.47474    best : 1.27086\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27143     accuracy : 0.51852\n",
      "VALID -> loss : 1.29706     accuracy : 0.48472    best : 1.27086\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26798     accuracy : 0.51984\n",
      "VALID -> loss : 1.28827     accuracy : 0.46357    best : 1.27086\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24097     accuracy : 0.53131\n",
      "VALID -> loss : 1.29418     accuracy : 0.47297    best : 1.27086\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23181     accuracy : 0.52954\n",
      "VALID -> loss : 1.24708     accuracy : 0.50353    best : 1.24708\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22121     accuracy : 0.53645\n",
      "VALID -> loss : 1.31137     accuracy : 0.46063    best : 1.24708\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18971     accuracy : 0.56011\n",
      "VALID -> loss : 1.80344     accuracy : 0.42362    best : 1.24708\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16616     accuracy : 0.56864\n",
      "VALID -> loss : 1.26593     accuracy : 0.50705    best : 1.24708\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12981     accuracy : 0.58936\n",
      "VALID -> loss : 1.18235     accuracy : 0.54407    best : 1.18235\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10579     accuracy : 0.60200\n",
      "VALID -> loss : 1.12285     accuracy : 0.58226    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10046     accuracy : 0.60538\n",
      "VALID -> loss : 1.12580     accuracy : 0.59636    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10094     accuracy : 0.60567\n",
      "VALID -> loss : 1.29380     accuracy : 0.48237    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11662     accuracy : 0.59186\n",
      "VALID -> loss : 1.21739     accuracy : 0.55699    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11078     accuracy : 0.59245\n",
      "VALID -> loss : 1.21319     accuracy : 0.54465    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11529     accuracy : 0.59509\n",
      "VALID -> loss : 1.55623     accuracy : 0.42127    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.09123     accuracy : 0.60215\n",
      "VALID -> loss : 1.39088     accuracy : 0.50470    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07808     accuracy : 0.62169\n",
      "VALID -> loss : 1.17607     accuracy : 0.58519    best : 1.12285\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03306     accuracy : 0.64477\n",
      "VALID -> loss : 1.05918     accuracy : 0.62397    best : 1.05918\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98987     accuracy : 0.66005\n",
      "VALID -> loss : 1.05011     accuracy : 0.63161    best : 1.05011\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95931     accuracy : 0.67754\n",
      "VALID -> loss : 1.02211     accuracy : 0.63807    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95004     accuracy : 0.67945\n",
      "VALID -> loss : 1.02225     accuracy : 0.64630    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96470     accuracy : 0.67578\n",
      "VALID -> loss : 1.04890     accuracy : 0.62103    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97795     accuracy : 0.66520\n",
      "VALID -> loss : 1.13556     accuracy : 0.57286    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00608     accuracy : 0.64624\n",
      "VALID -> loss : 4.72076     accuracy : 0.39835    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02250     accuracy : 0.64403\n",
      "VALID -> loss : 1.25744     accuracy : 0.54113    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00614     accuracy : 0.65079\n",
      "VALID -> loss : 1.08837     accuracy : 0.61457    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97371     accuracy : 0.66520\n",
      "VALID -> loss : 1.12123     accuracy : 0.59342    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92449     accuracy : 0.68519\n",
      "VALID -> loss : 1.04943     accuracy : 0.63690    best : 1.02211\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88019     accuracy : 0.70503\n",
      "VALID -> loss : 0.98028     accuracy : 0.65746    best : 0.98028\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.83608     accuracy : 0.72766\n",
      "VALID -> loss : 0.97405     accuracy : 0.66275    best : 0.97405\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.55167     accuracy : 0.36635\n",
      "VALID -> loss : 1.38261     accuracy : 0.39271    best : 1.38261\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.36424     accuracy : 0.40558\n",
      "VALID -> loss : 1.32331     accuracy : 0.41681    best : 1.32331\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.33382     accuracy : 0.43233\n",
      "VALID -> loss : 1.31623     accuracy : 0.42446    best : 1.31623\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31626     accuracy : 0.45790\n",
      "VALID -> loss : 1.29665     accuracy : 0.46267    best : 1.29665\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.30258     accuracy : 0.46892\n",
      "VALID -> loss : 1.28847     accuracy : 0.46678    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.30650     accuracy : 0.47289\n",
      "VALID -> loss : 1.29959     accuracy : 0.44680    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.30351     accuracy : 0.47186\n",
      "VALID -> loss : 1.34130     accuracy : 0.39330    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.29660     accuracy : 0.46848\n",
      "VALID -> loss : 1.59995     accuracy : 0.40682    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.29882     accuracy : 0.46319\n",
      "VALID -> loss : 1.41593     accuracy : 0.37507    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27502     accuracy : 0.47935\n",
      "VALID -> loss : 1.35082     accuracy : 0.40858    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26358     accuracy : 0.48846\n",
      "VALID -> loss : 1.35292     accuracy : 0.40741    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24217     accuracy : 0.49743\n",
      "VALID -> loss : 1.35386     accuracy : 0.41917    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23054     accuracy : 0.50654\n",
      "VALID -> loss : 1.45962     accuracy : 0.40388    best : 1.28847\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20205     accuracy : 0.52785\n",
      "VALID -> loss : 1.17853     accuracy : 0.53322    best : 1.17853\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18878     accuracy : 0.53946\n",
      "VALID -> loss : 1.17336     accuracy : 0.52557    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18546     accuracy : 0.54195\n",
      "VALID -> loss : 1.17469     accuracy : 0.54733    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19505     accuracy : 0.54210\n",
      "VALID -> loss : 1.23878     accuracy : 0.50676    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19299     accuracy : 0.53608\n",
      "VALID -> loss : 1.19583     accuracy : 0.51440    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21550     accuracy : 0.52814\n",
      "VALID -> loss : 1.37170     accuracy : 0.44268    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21742     accuracy : 0.52344\n",
      "VALID -> loss : 1.61206     accuracy : 0.40800    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19014     accuracy : 0.54813\n",
      "VALID -> loss : 2.04160     accuracy : 0.40035    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19234     accuracy : 0.53578\n",
      "VALID -> loss : 1.21346     accuracy : 0.49794    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.15526     accuracy : 0.56414\n",
      "VALID -> loss : 1.23299     accuracy : 0.49030    best : 1.17336\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12821     accuracy : 0.57428\n",
      "VALID -> loss : 1.14302     accuracy : 0.54497    best : 1.14302\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11353     accuracy : 0.57943\n",
      "VALID -> loss : 1.12168     accuracy : 0.54909    best : 1.12168\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11159     accuracy : 0.58310\n",
      "VALID -> loss : 1.12040     accuracy : 0.55438    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10883     accuracy : 0.58384\n",
      "VALID -> loss : 1.17272     accuracy : 0.52675    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11999     accuracy : 0.57649\n",
      "VALID -> loss : 1.41593     accuracy : 0.47208    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12523     accuracy : 0.57428\n",
      "VALID -> loss : 1.87636     accuracy : 0.41387    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16812     accuracy : 0.54857\n",
      "VALID -> loss : 1.27652     accuracy : 0.48325    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.13600     accuracy : 0.56591\n",
      "VALID -> loss : 1.76882     accuracy : 0.29982    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11899     accuracy : 0.57561\n",
      "VALID -> loss : 1.24183     accuracy : 0.50852    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08534     accuracy : 0.59324\n",
      "VALID -> loss : 1.30442     accuracy : 0.47325    best : 1.12040\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05134     accuracy : 0.60735\n",
      "VALID -> loss : 1.08272     accuracy : 0.57084    best : 1.08272\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03309     accuracy : 0.62351\n",
      "VALID -> loss : 1.06970     accuracy : 0.58613    best : 1.06970\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.48630     accuracy : 0.42954\n",
      "VALID -> loss : 1.37753     accuracy : 0.46561    best : 1.37753\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.32255     accuracy : 0.47641\n",
      "VALID -> loss : 1.31898     accuracy : 0.47384    best : 1.31898\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28819     accuracy : 0.49508\n",
      "VALID -> loss : 1.38108     accuracy : 0.41505    best : 1.31898\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26597     accuracy : 0.50389\n",
      "VALID -> loss : 1.27127     accuracy : 0.46267    best : 1.27127\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24268     accuracy : 0.52212\n",
      "VALID -> loss : 1.22654     accuracy : 0.53145    best : 1.22654\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24080     accuracy : 0.52594\n",
      "VALID -> loss : 1.21999     accuracy : 0.53851    best : 1.21999\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23316     accuracy : 0.52711\n",
      "VALID -> loss : 1.37792     accuracy : 0.44621    best : 1.21999\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22866     accuracy : 0.52814\n",
      "VALID -> loss : 1.21926     accuracy : 0.52734    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22246     accuracy : 0.52447\n",
      "VALID -> loss : 1.39723     accuracy : 0.41446    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19776     accuracy : 0.54284\n",
      "VALID -> loss : 1.28630     accuracy : 0.49794    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18457     accuracy : 0.55621\n",
      "VALID -> loss : 1.26028     accuracy : 0.48383    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14773     accuracy : 0.57796\n",
      "VALID -> loss : 1.35064     accuracy : 0.48325    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10846     accuracy : 0.59882\n",
      "VALID -> loss : 1.26844     accuracy : 0.52440    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07149     accuracy : 0.62292\n",
      "VALID -> loss : 1.21469     accuracy : 0.54086    best : 1.21469\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03268     accuracy : 0.64085\n",
      "VALID -> loss : 1.08493     accuracy : 0.60847    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02649     accuracy : 0.64629\n",
      "VALID -> loss : 1.08813     accuracy : 0.60259    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03569     accuracy : 0.64306\n",
      "VALID -> loss : 1.43640     accuracy : 0.44150    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06891     accuracy : 0.63556\n",
      "VALID -> loss : 1.70762     accuracy : 0.45914    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07596     accuracy : 0.61499\n",
      "VALID -> loss : 1.23758     accuracy : 0.54850    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06601     accuracy : 0.61852\n",
      "VALID -> loss : 1.60085     accuracy : 0.42975    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07099     accuracy : 0.62131\n",
      "VALID -> loss : 3.11065     accuracy : 0.39800    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01778     accuracy : 0.64879\n",
      "VALID -> loss : 1.12604     accuracy : 0.59377    best : 1.08493\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96968     accuracy : 0.66921\n",
      "VALID -> loss : 1.06356     accuracy : 0.63786    best : 1.06356\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91490     accuracy : 0.70096\n",
      "VALID -> loss : 1.00419     accuracy : 0.65138    best : 1.00419\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.87792     accuracy : 0.71668\n",
      "VALID -> loss : 0.99897     accuracy : 0.65785    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88065     accuracy : 0.71903\n",
      "VALID -> loss : 1.00564     accuracy : 0.65608    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.87643     accuracy : 0.71536\n",
      "VALID -> loss : 1.01692     accuracy : 0.64198    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90533     accuracy : 0.70345\n",
      "VALID -> loss : 1.66300     accuracy : 0.44797    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95283     accuracy : 0.67583\n",
      "VALID -> loss : 2.53610     accuracy : 0.28160    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95821     accuracy : 0.66804\n",
      "VALID -> loss : 1.07481     accuracy : 0.62904    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96475     accuracy : 0.66613\n",
      "VALID -> loss : 1.61272     accuracy : 0.45503    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91714     accuracy : 0.69273\n",
      "VALID -> loss : 1.07089     accuracy : 0.63374    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84646     accuracy : 0.71888\n",
      "VALID -> loss : 1.02450     accuracy : 0.65256    best : 0.99897\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.77737     accuracy : 0.75650\n",
      "VALID -> loss : 0.94489     accuracy : 0.68019    best : 0.94489\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.74317     accuracy : 0.77120\n",
      "VALID -> loss : 0.94505     accuracy : 0.68313    best : 0.94489\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.52793     accuracy : 0.38913\n",
      "VALID -> loss : 1.36844     accuracy : 0.45032    best : 1.36844\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.33521     accuracy : 0.46877\n",
      "VALID -> loss : 1.30486     accuracy : 0.47208    best : 1.30486\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28483     accuracy : 0.50463\n",
      "VALID -> loss : 1.28285     accuracy : 0.49559    best : 1.28285\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.25511     accuracy : 0.52623\n",
      "VALID -> loss : 1.22972     accuracy : 0.54086    best : 1.22972\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22702     accuracy : 0.54857\n",
      "VALID -> loss : 1.21663     accuracy : 0.54086    best : 1.21663\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21680     accuracy : 0.55783\n",
      "VALID -> loss : 1.20383     accuracy : 0.54086    best : 1.20383\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21881     accuracy : 0.55871\n",
      "VALID -> loss : 2.07804     accuracy : 0.39271    best : 1.20383\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22741     accuracy : 0.54695\n",
      "VALID -> loss : 2.22704     accuracy : 0.39859    best : 1.20383\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21136     accuracy : 0.55621\n",
      "VALID -> loss : 1.20842     accuracy : 0.56496    best : 1.20383\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19525     accuracy : 0.55562\n",
      "VALID -> loss : 1.26683     accuracy : 0.50323    best : 1.20383\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14872     accuracy : 0.57825\n",
      "VALID -> loss : 1.19280     accuracy : 0.56790    best : 1.19280\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12037     accuracy : 0.59897\n",
      "VALID -> loss : 1.41571     accuracy : 0.45150    best : 1.19280\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05784     accuracy : 0.62954\n",
      "VALID -> loss : 1.14946     accuracy : 0.57260    best : 1.14946\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01416     accuracy : 0.65364\n",
      "VALID -> loss : 1.07314     accuracy : 0.60905    best : 1.07314\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98068     accuracy : 0.66965\n",
      "VALID -> loss : 1.03851     accuracy : 0.62316    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97235     accuracy : 0.67597\n",
      "VALID -> loss : 1.06497     accuracy : 0.61728    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98915     accuracy : 0.66716\n",
      "VALID -> loss : 1.14262     accuracy : 0.57848    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00232     accuracy : 0.65658\n",
      "VALID -> loss : 1.13506     accuracy : 0.59436    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02969     accuracy : 0.63497\n",
      "VALID -> loss : 1.15013     accuracy : 0.59730    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01803     accuracy : 0.64702\n",
      "VALID -> loss : 1.24628     accuracy : 0.52557    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01523     accuracy : 0.64100\n",
      "VALID -> loss : 1.43313     accuracy : 0.51969    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96881     accuracy : 0.66877\n",
      "VALID -> loss : 1.09186     accuracy : 0.60729    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91821     accuracy : 0.68964\n",
      "VALID -> loss : 1.09060     accuracy : 0.61611    best : 1.03851\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85656     accuracy : 0.71492\n",
      "VALID -> loss : 0.98541     accuracy : 0.64903    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80584     accuracy : 0.73519\n",
      "VALID -> loss : 0.99045     accuracy : 0.65491    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80671     accuracy : 0.73828\n",
      "VALID -> loss : 0.99081     accuracy : 0.65667    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.81023     accuracy : 0.73167\n",
      "VALID -> loss : 1.04619     accuracy : 0.63845    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84507     accuracy : 0.71639\n",
      "VALID -> loss : 1.15731     accuracy : 0.59259    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89746     accuracy : 0.69699\n",
      "VALID -> loss : 1.41768     accuracy : 0.53028    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91963     accuracy : 0.68376\n",
      "VALID -> loss : 1.35479     accuracy : 0.51264    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89294     accuracy : 0.68979\n",
      "VALID -> loss : 1.10275     accuracy : 0.60082    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.83391     accuracy : 0.72006\n",
      "VALID -> loss : 1.02784     accuracy : 0.64080    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.76401     accuracy : 0.74754\n",
      "VALID -> loss : 1.28734     accuracy : 0.57319    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.68732     accuracy : 0.77443\n",
      "VALID -> loss : 1.02032     accuracy : 0.64609    best : 0.98541\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.64403     accuracy : 0.79633\n",
      "VALID -> loss : 0.96456     accuracy : 0.66549    best : 0.96456\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.47188     accuracy : 0.44453\n",
      "VALID -> loss : 1.43718     accuracy : 0.39330    best : 1.43718\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.30920     accuracy : 0.49008\n",
      "VALID -> loss : 1.36011     accuracy : 0.43680    best : 1.36011\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27084     accuracy : 0.51256\n",
      "VALID -> loss : 1.30893     accuracy : 0.46208    best : 1.30893\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23145     accuracy : 0.54372\n",
      "VALID -> loss : 1.23835     accuracy : 0.52087    best : 1.23835\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20731     accuracy : 0.56165\n",
      "VALID -> loss : 1.18483     accuracy : 0.56261    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19526     accuracy : 0.56458\n",
      "VALID -> loss : 1.19078     accuracy : 0.55850    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19411     accuracy : 0.55577\n",
      "VALID -> loss : 1.28978     accuracy : 0.43621    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18772     accuracy : 0.55650\n",
      "VALID -> loss : 1.87105     accuracy : 0.33804    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17646     accuracy : 0.56076\n",
      "VALID -> loss : 1.90203     accuracy : 0.38918    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14926     accuracy : 0.57752\n",
      "VALID -> loss : 2.28197     accuracy : 0.39683    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14370     accuracy : 0.57810\n",
      "VALID -> loss : 1.37326     accuracy : 0.42504    best : 1.18483\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11018     accuracy : 0.59853\n",
      "VALID -> loss : 1.18442     accuracy : 0.52440    best : 1.18442\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06255     accuracy : 0.62469\n",
      "VALID -> loss : 1.25703     accuracy : 0.54380    best : 1.18442\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01176     accuracy : 0.65320\n",
      "VALID -> loss : 1.05026     accuracy : 0.61493    best : 1.05026\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99027     accuracy : 0.66495\n",
      "VALID -> loss : 1.02269     accuracy : 0.63257    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97865     accuracy : 0.67201\n",
      "VALID -> loss : 1.02655     accuracy : 0.63374    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98508     accuracy : 0.66201\n",
      "VALID -> loss : 1.20632     accuracy : 0.58730    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00537     accuracy : 0.65643\n",
      "VALID -> loss : 1.16962     accuracy : 0.56320    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01633     accuracy : 0.65040\n",
      "VALID -> loss : 1.38920     accuracy : 0.44915    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02322     accuracy : 0.63718\n",
      "VALID -> loss : 1.28349     accuracy : 0.48795    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00578     accuracy : 0.65349\n",
      "VALID -> loss : 1.43992     accuracy : 0.52028    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95738     accuracy : 0.67318\n",
      "VALID -> loss : 1.02271     accuracy : 0.63492    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90845     accuracy : 0.69140\n",
      "VALID -> loss : 1.11821     accuracy : 0.59259    best : 1.02269\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85315     accuracy : 0.71683\n",
      "VALID -> loss : 0.96432     accuracy : 0.66373    best : 0.96432\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.81288     accuracy : 0.73666\n",
      "VALID -> loss : 0.93405     accuracy : 0.67137    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80823     accuracy : 0.74166\n",
      "VALID -> loss : 0.93705     accuracy : 0.67784    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.81716     accuracy : 0.73490\n",
      "VALID -> loss : 0.97550     accuracy : 0.66373    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85310     accuracy : 0.71477\n",
      "VALID -> loss : 1.04542     accuracy : 0.60611    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89005     accuracy : 0.70345\n",
      "VALID -> loss : 3.10910     accuracy : 0.20635    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92340     accuracy : 0.68288\n",
      "VALID -> loss : 1.85129     accuracy : 0.42210    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89524     accuracy : 0.69728\n",
      "VALID -> loss : 1.12369     accuracy : 0.59965    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.82311     accuracy : 0.72476\n",
      "VALID -> loss : 1.09070     accuracy : 0.62787    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.77440     accuracy : 0.75180\n",
      "VALID -> loss : 1.01468     accuracy : 0.64315    best : 0.93405\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.69763     accuracy : 0.77605\n",
      "VALID -> loss : 0.91643     accuracy : 0.68136    best : 0.91643\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.66203     accuracy : 0.80588\n",
      "VALID -> loss : 0.89469     accuracy : 0.68665    best : 0.89469\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.62127     accuracy : 0.33730\n",
      "VALID -> loss : 1.49309     accuracy : 0.39013    best : 1.49309\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.37740     accuracy : 0.43460\n",
      "VALID -> loss : 1.35262     accuracy : 0.44947    best : 1.35262\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31893     accuracy : 0.46223\n",
      "VALID -> loss : 1.29948     accuracy : 0.45946    best : 1.29948\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.29469     accuracy : 0.46972\n",
      "VALID -> loss : 1.27691     accuracy : 0.47297    best : 1.27691\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27852     accuracy : 0.48045\n",
      "VALID -> loss : 1.27630     accuracy : 0.47591    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27299     accuracy : 0.47825\n",
      "VALID -> loss : 1.28526     accuracy : 0.45006    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27454     accuracy : 0.48192\n",
      "VALID -> loss : 1.31302     accuracy : 0.45123    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26755     accuracy : 0.49074\n",
      "VALID -> loss : 3.64466     accuracy : 0.16040    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27202     accuracy : 0.48148\n",
      "VALID -> loss : 1.60030     accuracy : 0.34489    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26300     accuracy : 0.48413\n",
      "VALID -> loss : 1.32754     accuracy : 0.44771    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24181     accuracy : 0.49691\n",
      "VALID -> loss : 1.34873     accuracy : 0.43126    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22005     accuracy : 0.51044\n",
      "VALID -> loss : 1.31598     accuracy : 0.47062    best : 1.27630\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19413     accuracy : 0.53616\n",
      "VALID -> loss : 1.24571     accuracy : 0.50294    best : 1.24571\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.15901     accuracy : 0.55923\n",
      "VALID -> loss : 1.21157     accuracy : 0.53055    best : 1.21157\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14576     accuracy : 0.57407\n",
      "VALID -> loss : 1.17514     accuracy : 0.55699    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.13565     accuracy : 0.57496\n",
      "VALID -> loss : 1.28144     accuracy : 0.47944    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.13708     accuracy : 0.57128\n",
      "VALID -> loss : 1.21099     accuracy : 0.52526    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14203     accuracy : 0.57172\n",
      "VALID -> loss : 1.56323     accuracy : 0.43361    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16688     accuracy : 0.55967\n",
      "VALID -> loss : 2.41901     accuracy : 0.18860    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17213     accuracy : 0.56026\n",
      "VALID -> loss : 1.59599     accuracy : 0.38660    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12526     accuracy : 0.58671\n",
      "VALID -> loss : 1.36832     accuracy : 0.47709    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08484     accuracy : 0.60450\n",
      "VALID -> loss : 1.61377     accuracy : 0.42891    best : 1.17514\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03280     accuracy : 0.63110\n",
      "VALID -> loss : 1.07865     accuracy : 0.61398    best : 1.07865\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00098     accuracy : 0.64242\n",
      "VALID -> loss : 1.06671     accuracy : 0.61692    best : 1.06671\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96869     accuracy : 0.66711\n",
      "VALID -> loss : 1.03521     accuracy : 0.62926    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96182     accuracy : 0.66887\n",
      "VALID -> loss : 1.04303     accuracy : 0.62103    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97034     accuracy : 0.66035\n",
      "VALID -> loss : 1.26778     accuracy : 0.49001    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98128     accuracy : 0.64903\n",
      "VALID -> loss : 1.08491     accuracy : 0.60341    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99642     accuracy : 0.64609\n",
      "VALID -> loss : 1.26191     accuracy : 0.52938    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02498     accuracy : 0.63330\n",
      "VALID -> loss : 1.08738     accuracy : 0.60400    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98570     accuracy : 0.64580\n",
      "VALID -> loss : 1.60197     accuracy : 0.43831    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97113     accuracy : 0.65226\n",
      "VALID -> loss : 1.38521     accuracy : 0.51116    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90342     accuracy : 0.68665\n",
      "VALID -> loss : 1.06984     accuracy : 0.62162    best : 1.03521\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.87275     accuracy : 0.70341\n",
      "VALID -> loss : 1.01851     accuracy : 0.63396    best : 1.01851\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.82951     accuracy : 0.72281\n",
      "VALID -> loss : 0.96303     accuracy : 0.65511    best : 0.96303\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.39896     accuracy : 0.45849\n",
      "VALID -> loss : 1.34267     accuracy : 0.41975    best : 1.34267\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.29991     accuracy : 0.48832\n",
      "VALID -> loss : 1.27619     accuracy : 0.49853    best : 1.27619\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28053     accuracy : 0.49993\n",
      "VALID -> loss : 1.35506     accuracy : 0.43621    best : 1.27619\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.25600     accuracy : 0.52079\n",
      "VALID -> loss : 1.25050     accuracy : 0.50794    best : 1.25050\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23050     accuracy : 0.53813\n",
      "VALID -> loss : 1.22128     accuracy : 0.53557    best : 1.22128\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22988     accuracy : 0.54195\n",
      "VALID -> loss : 1.21926     accuracy : 0.53439    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22861     accuracy : 0.53608\n",
      "VALID -> loss : 1.35697     accuracy : 0.47678    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23676     accuracy : 0.53593\n",
      "VALID -> loss : 2.00896     accuracy : 0.39212    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23787     accuracy : 0.53005\n",
      "VALID -> loss : 1.38152     accuracy : 0.46208    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21095     accuracy : 0.54460\n",
      "VALID -> loss : 1.50398     accuracy : 0.40858    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18509     accuracy : 0.55827\n",
      "VALID -> loss : 1.26096     accuracy : 0.50265    best : 1.21926\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.15289     accuracy : 0.56988\n",
      "VALID -> loss : 1.17870     accuracy : 0.54321    best : 1.17870\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11432     accuracy : 0.59295\n",
      "VALID -> loss : 1.10416     accuracy : 0.59612    best : 1.10416\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06764     accuracy : 0.61866\n",
      "VALID -> loss : 1.05240     accuracy : 0.62257    best : 1.05240\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04257     accuracy : 0.63659\n",
      "VALID -> loss : 1.04812     accuracy : 0.62551    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02357     accuracy : 0.64394\n",
      "VALID -> loss : 1.05455     accuracy : 0.62140    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02980     accuracy : 0.63850\n",
      "VALID -> loss : 1.09976     accuracy : 0.59200    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04918     accuracy : 0.63248\n",
      "VALID -> loss : 1.35783     accuracy : 0.44209    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08170     accuracy : 0.61661\n",
      "VALID -> loss : 1.13724     accuracy : 0.59847    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07066     accuracy : 0.61763\n",
      "VALID -> loss : 1.88031     accuracy : 0.44386    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06315     accuracy : 0.62645\n",
      "VALID -> loss : 1.30647     accuracy : 0.47208    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02936     accuracy : 0.63806\n",
      "VALID -> loss : 1.11713     accuracy : 0.56908    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97114     accuracy : 0.66289\n",
      "VALID -> loss : 1.06202     accuracy : 0.59553    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90982     accuracy : 0.69361\n",
      "VALID -> loss : 1.04974     accuracy : 0.62669    best : 1.04812\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.86935     accuracy : 0.70816\n",
      "VALID -> loss : 0.96811     accuracy : 0.66020    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.86656     accuracy : 0.71447\n",
      "VALID -> loss : 0.99776     accuracy : 0.64962    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88298     accuracy : 0.70228\n",
      "VALID -> loss : 1.01019     accuracy : 0.64374    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90621     accuracy : 0.69214\n",
      "VALID -> loss : 1.14890     accuracy : 0.56320    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96108     accuracy : 0.66436\n",
      "VALID -> loss : 1.85706     accuracy : 0.44856    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97081     accuracy : 0.65746\n",
      "VALID -> loss : 1.27572     accuracy : 0.51029    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94389     accuracy : 0.67171\n",
      "VALID -> loss : 1.93583     accuracy : 0.52322    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93574     accuracy : 0.67245\n",
      "VALID -> loss : 1.16101     accuracy : 0.54145    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84632     accuracy : 0.71095\n",
      "VALID -> loss : 1.24585     accuracy : 0.58142    best : 0.96811\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.79533     accuracy : 0.73490\n",
      "VALID -> loss : 0.95431     accuracy : 0.66784    best : 0.95431\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.74314     accuracy : 0.75915\n",
      "VALID -> loss : 0.92926     accuracy : 0.67372    best : 0.92926\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.47382     accuracy : 0.43012\n",
      "VALID -> loss : 1.33603     accuracy : 0.43151    best : 1.33603\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31910     accuracy : 0.48185\n",
      "VALID -> loss : 1.28463     accuracy : 0.48148    best : 1.28463\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27509     accuracy : 0.49787\n",
      "VALID -> loss : 1.28645     accuracy : 0.48971    best : 1.28463\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23791     accuracy : 0.52506\n",
      "VALID -> loss : 1.21792     accuracy : 0.51205    best : 1.21792\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21440     accuracy : 0.54225\n",
      "VALID -> loss : 1.19961     accuracy : 0.52910    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20590     accuracy : 0.54827\n",
      "VALID -> loss : 1.22674     accuracy : 0.48677    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20403     accuracy : 0.54342\n",
      "VALID -> loss : 1.26905     accuracy : 0.49089    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20234     accuracy : 0.54386\n",
      "VALID -> loss : 2.18197     accuracy : 0.39859    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19484     accuracy : 0.55004\n",
      "VALID -> loss : 1.43726     accuracy : 0.43386    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20326     accuracy : 0.54930\n",
      "VALID -> loss : 2.43433     accuracy : 0.32275    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17266     accuracy : 0.56238\n",
      "VALID -> loss : 1.40376     accuracy : 0.46678    best : 1.19961\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12260     accuracy : 0.58486\n",
      "VALID -> loss : 1.17127     accuracy : 0.55379    best : 1.17127\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.09988     accuracy : 0.60749\n",
      "VALID -> loss : 1.10180     accuracy : 0.59259    best : 1.10180\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04518     accuracy : 0.63630\n",
      "VALID -> loss : 1.05930     accuracy : 0.62199    best : 1.05930\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01515     accuracy : 0.65467\n",
      "VALID -> loss : 1.03553     accuracy : 0.62787    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00768     accuracy : 0.65819\n",
      "VALID -> loss : 1.03820     accuracy : 0.62493    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01010     accuracy : 0.64879\n",
      "VALID -> loss : 1.07924     accuracy : 0.62140    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03961     accuracy : 0.63894\n",
      "VALID -> loss : 1.10878     accuracy : 0.58613    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05040     accuracy : 0.63365\n",
      "VALID -> loss : 1.42291     accuracy : 0.47090    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04653     accuracy : 0.62557\n",
      "VALID -> loss : 1.18515     accuracy : 0.56379    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04157     accuracy : 0.62616\n",
      "VALID -> loss : 1.18189     accuracy : 0.53557    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99847     accuracy : 0.65614\n",
      "VALID -> loss : 1.05057     accuracy : 0.62845    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95442     accuracy : 0.67083\n",
      "VALID -> loss : 1.04905     accuracy : 0.63316    best : 1.03553\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90219     accuracy : 0.69449\n",
      "VALID -> loss : 1.02467     accuracy : 0.62845    best : 1.02467\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85819     accuracy : 0.71712\n",
      "VALID -> loss : 0.97214     accuracy : 0.66373    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84870     accuracy : 0.71932\n",
      "VALID -> loss : 0.99976     accuracy : 0.64903    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85826     accuracy : 0.71932\n",
      "VALID -> loss : 1.14799     accuracy : 0.58848    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89873     accuracy : 0.69493\n",
      "VALID -> loss : 1.44842     accuracy : 0.50029    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93082     accuracy : 0.67465\n",
      "VALID -> loss : 1.25928     accuracy : 0.51558    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95524     accuracy : 0.66510\n",
      "VALID -> loss : 1.10089     accuracy : 0.59788    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92232     accuracy : 0.68215\n",
      "VALID -> loss : 1.14482     accuracy : 0.56026    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89368     accuracy : 0.69052\n",
      "VALID -> loss : 1.45237     accuracy : 0.54556    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.81737     accuracy : 0.72711\n",
      "VALID -> loss : 1.02845     accuracy : 0.64080    best : 0.97214\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.74373     accuracy : 0.75812\n",
      "VALID -> loss : 0.96633     accuracy : 0.65961    best : 0.96633\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.69939     accuracy : 0.77913\n",
      "VALID -> loss : 0.93952     accuracy : 0.67019    best : 0.93952\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.55620     accuracy : 0.35371\n",
      "VALID -> loss : 1.38411     accuracy : 0.44797    best : 1.38411\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.36274     accuracy : 0.44702\n",
      "VALID -> loss : 1.30362     accuracy : 0.45503    best : 1.30362\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31448     accuracy : 0.47994\n",
      "VALID -> loss : 1.26889     accuracy : 0.49206    best : 1.26889\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27588     accuracy : 0.49978\n",
      "VALID -> loss : 1.33069     accuracy : 0.42152    best : 1.26889\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.25496     accuracy : 0.51286\n",
      "VALID -> loss : 1.24245     accuracy : 0.49677    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.25198     accuracy : 0.51932\n",
      "VALID -> loss : 1.24666     accuracy : 0.49265    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24150     accuracy : 0.51536\n",
      "VALID -> loss : 1.31066     accuracy : 0.46091    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24817     accuracy : 0.50522\n",
      "VALID -> loss : 1.71076     accuracy : 0.32275    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22869     accuracy : 0.52256\n",
      "VALID -> loss : 1.90876     accuracy : 0.41387    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21583     accuracy : 0.53916\n",
      "VALID -> loss : 6.42570     accuracy : 0.39271    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19223     accuracy : 0.54886\n",
      "VALID -> loss : 2.02236     accuracy : 0.40212    best : 1.24245\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16300     accuracy : 0.57502\n",
      "VALID -> loss : 1.16005     accuracy : 0.56085    best : 1.16005\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11653     accuracy : 0.59618\n",
      "VALID -> loss : 1.21809     accuracy : 0.52557    best : 1.16005\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08192     accuracy : 0.61323\n",
      "VALID -> loss : 1.11206     accuracy : 0.57848    best : 1.11206\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05863     accuracy : 0.63424\n",
      "VALID -> loss : 1.09486     accuracy : 0.58848    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05283     accuracy : 0.63733\n",
      "VALID -> loss : 1.09558     accuracy : 0.58730    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05217     accuracy : 0.63262\n",
      "VALID -> loss : 1.22424     accuracy : 0.52205    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06386     accuracy : 0.62131\n",
      "VALID -> loss : 1.26576     accuracy : 0.50206    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08872     accuracy : 0.60911\n",
      "VALID -> loss : 1.14869     accuracy : 0.55556    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07162     accuracy : 0.61043\n",
      "VALID -> loss : 1.19265     accuracy : 0.57025    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04801     accuracy : 0.62763\n",
      "VALID -> loss : 1.30577     accuracy : 0.53086    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00705     accuracy : 0.64688\n",
      "VALID -> loss : 1.70697     accuracy : 0.46091    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97857     accuracy : 0.65863\n",
      "VALID -> loss : 1.12209     accuracy : 0.58671    best : 1.09486\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92822     accuracy : 0.68450\n",
      "VALID -> loss : 1.02556     accuracy : 0.62669    best : 1.02556\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88380     accuracy : 0.69831\n",
      "VALID -> loss : 0.99203     accuracy : 0.64433    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.87635     accuracy : 0.70507\n",
      "VALID -> loss : 1.00689     accuracy : 0.63904    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88280     accuracy : 0.69875\n",
      "VALID -> loss : 1.04811     accuracy : 0.63081    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91765     accuracy : 0.68699\n",
      "VALID -> loss : 1.42361     accuracy : 0.51440    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95745     accuracy : 0.66833\n",
      "VALID -> loss : 1.07348     accuracy : 0.60905    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98099     accuracy : 0.65511\n",
      "VALID -> loss : 1.20540     accuracy : 0.55085    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94313     accuracy : 0.67157\n",
      "VALID -> loss : 1.27889     accuracy : 0.52499    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89466     accuracy : 0.69434\n",
      "VALID -> loss : 1.36429     accuracy : 0.52675    best : 0.99203\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85538     accuracy : 0.71154\n",
      "VALID -> loss : 0.97504     accuracy : 0.64844    best : 0.97504\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.78067     accuracy : 0.73975\n",
      "VALID -> loss : 0.95023     accuracy : 0.66961    best : 0.95023\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.72870     accuracy : 0.76414\n",
      "VALID -> loss : 0.93412     accuracy : 0.66961    best : 0.93412\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.51688     accuracy : 0.39295\n",
      "VALID -> loss : 1.37617     accuracy : 0.43563    best : 1.37617\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.33429     accuracy : 0.45702\n",
      "VALID -> loss : 1.28724     accuracy : 0.46796    best : 1.28724\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28932     accuracy : 0.47098\n",
      "VALID -> loss : 1.25208     accuracy : 0.49324    best : 1.25208\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.26230     accuracy : 0.49126\n",
      "VALID -> loss : 1.24344     accuracy : 0.50323    best : 1.24344\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24342     accuracy : 0.50566\n",
      "VALID -> loss : 1.22412     accuracy : 0.51440    best : 1.22412\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23557     accuracy : 0.50478\n",
      "VALID -> loss : 1.22062     accuracy : 0.52146    best : 1.22062\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23947     accuracy : 0.51095\n",
      "VALID -> loss : 1.25858     accuracy : 0.45267    best : 1.22062\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23696     accuracy : 0.51756\n",
      "VALID -> loss : 1.49634     accuracy : 0.41035    best : 1.22062\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23393     accuracy : 0.51697\n",
      "VALID -> loss : 2.24706     accuracy : 0.29630    best : 1.22062\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22494     accuracy : 0.52182\n",
      "VALID -> loss : 1.20613     accuracy : 0.54203    best : 1.20613\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20176     accuracy : 0.54122\n",
      "VALID -> loss : 1.63542     accuracy : 0.40094    best : 1.20613\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18525     accuracy : 0.55327\n",
      "VALID -> loss : 1.17666     accuracy : 0.56085    best : 1.17666\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.13357     accuracy : 0.58310\n",
      "VALID -> loss : 1.27494     accuracy : 0.48266    best : 1.17666\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08505     accuracy : 0.61308\n",
      "VALID -> loss : 1.08723     accuracy : 0.60376    best : 1.08723\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05741     accuracy : 0.62880\n",
      "VALID -> loss : 1.05580     accuracy : 0.63081    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04920     accuracy : 0.63071\n",
      "VALID -> loss : 1.06082     accuracy : 0.62140    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06419     accuracy : 0.62087\n",
      "VALID -> loss : 1.12574     accuracy : 0.57790    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07683     accuracy : 0.61073\n",
      "VALID -> loss : 1.19659     accuracy : 0.54027    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08543     accuracy : 0.61278\n",
      "VALID -> loss : 1.59024     accuracy : 0.47266    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10301     accuracy : 0.60191\n",
      "VALID -> loss : 2.76760     accuracy : 0.40800    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06056     accuracy : 0.62351\n",
      "VALID -> loss : 1.13653     accuracy : 0.58025    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04451     accuracy : 0.63733\n",
      "VALID -> loss : 1.42366     accuracy : 0.52616    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99792     accuracy : 0.65173\n",
      "VALID -> loss : 1.08079     accuracy : 0.59671    best : 1.05580\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94738     accuracy : 0.67700\n",
      "VALID -> loss : 0.97374     accuracy : 0.65961    best : 0.97374\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90562     accuracy : 0.69067\n",
      "VALID -> loss : 0.95679     accuracy : 0.66608    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89769     accuracy : 0.70051\n",
      "VALID -> loss : 0.96188     accuracy : 0.66196    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90352     accuracy : 0.69390\n",
      "VALID -> loss : 1.01663     accuracy : 0.63962    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93197     accuracy : 0.68082\n",
      "VALID -> loss : 1.24815     accuracy : 0.55203    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95071     accuracy : 0.66965\n",
      "VALID -> loss : 1.11262     accuracy : 0.60847    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96026     accuracy : 0.66701\n",
      "VALID -> loss : 1.14041     accuracy : 0.56261    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94450     accuracy : 0.66995\n",
      "VALID -> loss : 1.74639     accuracy : 0.50794    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90874     accuracy : 0.69023\n",
      "VALID -> loss : 1.17148     accuracy : 0.57437    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84302     accuracy : 0.71271\n",
      "VALID -> loss : 1.05113     accuracy : 0.61964    best : 0.95679\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.78519     accuracy : 0.74328\n",
      "VALID -> loss : 0.93384     accuracy : 0.66314    best : 0.93384\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.73721     accuracy : 0.76018\n",
      "VALID -> loss : 0.89644     accuracy : 0.67960    best : 0.89644\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.45900     accuracy : 0.44033\n",
      "VALID -> loss : 1.39742     accuracy : 0.40893    best : 1.39742\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31027     accuracy : 0.47707\n",
      "VALID -> loss : 1.35659     accuracy : 0.40717    best : 1.35659\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28372     accuracy : 0.49324\n",
      "VALID -> loss : 1.29176     accuracy : 0.45417    best : 1.29176\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24936     accuracy : 0.51852\n",
      "VALID -> loss : 1.22650     accuracy : 0.52644    best : 1.22650\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22952     accuracy : 0.53042\n",
      "VALID -> loss : 1.21772     accuracy : 0.53760    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22753     accuracy : 0.53395\n",
      "VALID -> loss : 1.22426     accuracy : 0.51998    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22136     accuracy : 0.54042\n",
      "VALID -> loss : 1.27034     accuracy : 0.50235    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22140     accuracy : 0.53939\n",
      "VALID -> loss : 1.22963     accuracy : 0.53290    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21686     accuracy : 0.54233\n",
      "VALID -> loss : 1.89943     accuracy : 0.39542    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19871     accuracy : 0.54909\n",
      "VALID -> loss : 1.57965     accuracy : 0.36957    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18046     accuracy : 0.56555\n",
      "VALID -> loss : 1.26391     accuracy : 0.50646    best : 1.21772\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.14516     accuracy : 0.58010\n",
      "VALID -> loss : 1.17067     accuracy : 0.56345    best : 1.17067\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11088     accuracy : 0.59818\n",
      "VALID -> loss : 1.25975     accuracy : 0.52174    best : 1.17067\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08729     accuracy : 0.61787\n",
      "VALID -> loss : 1.11296     accuracy : 0.59401    best : 1.11296\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06487     accuracy : 0.62919\n",
      "VALID -> loss : 1.08454     accuracy : 0.60576    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05396     accuracy : 0.63183\n",
      "VALID -> loss : 1.10386     accuracy : 0.58108    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05686     accuracy : 0.62860\n",
      "VALID -> loss : 1.16672     accuracy : 0.54524    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.07531     accuracy : 0.62184\n",
      "VALID -> loss : 1.21627     accuracy : 0.53349    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08022     accuracy : 0.61214\n",
      "VALID -> loss : 1.24572     accuracy : 0.54818    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08598     accuracy : 0.61199\n",
      "VALID -> loss : 1.93611     accuracy : 0.47767    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08547     accuracy : 0.60788\n",
      "VALID -> loss : 1.39595     accuracy : 0.49765    best : 1.08454\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05395     accuracy : 0.62919\n",
      "VALID -> loss : 1.05836     accuracy : 0.61692    best : 1.05836\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00521     accuracy : 0.65564\n",
      "VALID -> loss : 1.27052     accuracy : 0.52879    best : 1.05836\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96127     accuracy : 0.67093\n",
      "VALID -> loss : 1.01217     accuracy : 0.63807    best : 1.01217\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92465     accuracy : 0.68989\n",
      "VALID -> loss : 0.99335     accuracy : 0.65217    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92496     accuracy : 0.69489\n",
      "VALID -> loss : 1.02238     accuracy : 0.62985    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93453     accuracy : 0.68386\n",
      "VALID -> loss : 1.16294     accuracy : 0.57991    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96016     accuracy : 0.67504\n",
      "VALID -> loss : 1.24744     accuracy : 0.55170    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97496     accuracy : 0.65814\n",
      "VALID -> loss : 1.05157     accuracy : 0.63396    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97823     accuracy : 0.66740\n",
      "VALID -> loss : 1.10535     accuracy : 0.59694    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99503     accuracy : 0.65359\n",
      "VALID -> loss : 1.53388     accuracy : 0.51528    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94129     accuracy : 0.67945\n",
      "VALID -> loss : 1.14824     accuracy : 0.58989    best : 0.99335\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89511     accuracy : 0.69459\n",
      "VALID -> loss : 0.98417     accuracy : 0.66040    best : 0.98417\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.83767     accuracy : 0.72105\n",
      "VALID -> loss : 0.96309     accuracy : 0.65922    best : 0.96309\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80463     accuracy : 0.73942\n",
      "VALID -> loss : 0.95238     accuracy : 0.65805    best : 0.95238\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.40929     accuracy : 0.44952\n",
      "VALID -> loss : 1.37138     accuracy : 0.47501    best : 1.37138\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28548     accuracy : 0.50037\n",
      "VALID -> loss : 1.52846     accuracy : 0.40329    best : 1.37138\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.25453     accuracy : 0.52579\n",
      "VALID -> loss : 1.34763     accuracy : 0.42740    best : 1.34763\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21360     accuracy : 0.54960\n",
      "VALID -> loss : 1.19511     accuracy : 0.56261    best : 1.19511\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18334     accuracy : 0.57164\n",
      "VALID -> loss : 1.17638     accuracy : 0.56790    best : 1.17638\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17254     accuracy : 0.57370\n",
      "VALID -> loss : 1.17172     accuracy : 0.57672    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16995     accuracy : 0.57252\n",
      "VALID -> loss : 1.31854     accuracy : 0.53322    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17973     accuracy : 0.57149\n",
      "VALID -> loss : 1.48005     accuracy : 0.39565    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.17528     accuracy : 0.56179\n",
      "VALID -> loss : 4.25968     accuracy : 0.13757    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16907     accuracy : 0.57120\n",
      "VALID -> loss : 1.39919     accuracy : 0.45914    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.13748     accuracy : 0.58193\n",
      "VALID -> loss : 1.34485     accuracy : 0.41917    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08268     accuracy : 0.61484\n",
      "VALID -> loss : 1.41929     accuracy : 0.45973    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04859     accuracy : 0.62939\n",
      "VALID -> loss : 1.32132     accuracy : 0.48795    best : 1.17172\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99916     accuracy : 0.65202\n",
      "VALID -> loss : 1.04688     accuracy : 0.63022    best : 1.04688\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.96778     accuracy : 0.66569\n",
      "VALID -> loss : 1.02555     accuracy : 0.63022    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97000     accuracy : 0.67068\n",
      "VALID -> loss : 1.06666     accuracy : 0.60788    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97391     accuracy : 0.66319\n",
      "VALID -> loss : 1.16803     accuracy : 0.55262    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00224     accuracy : 0.65555\n",
      "VALID -> loss : 1.38874     accuracy : 0.48677    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01767     accuracy : 0.63924\n",
      "VALID -> loss : 1.53924     accuracy : 0.46267    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00929     accuracy : 0.64409\n",
      "VALID -> loss : 2.15456     accuracy : 0.42093    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99682     accuracy : 0.64761\n",
      "VALID -> loss : 1.11341     accuracy : 0.61493    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97110     accuracy : 0.65922\n",
      "VALID -> loss : 1.16583     accuracy : 0.57731    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92353     accuracy : 0.67818\n",
      "VALID -> loss : 1.30496     accuracy : 0.56026    best : 1.02555\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84931     accuracy : 0.70933\n",
      "VALID -> loss : 0.98545     accuracy : 0.64080    best : 0.98545\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80637     accuracy : 0.73652\n",
      "VALID -> loss : 0.95984     accuracy : 0.65667    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.80357     accuracy : 0.74019\n",
      "VALID -> loss : 0.96882     accuracy : 0.65315    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.81302     accuracy : 0.73196\n",
      "VALID -> loss : 1.08789     accuracy : 0.61728    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.83987     accuracy : 0.71932\n",
      "VALID -> loss : 1.17612     accuracy : 0.59436    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.85920     accuracy : 0.70801\n",
      "VALID -> loss : 2.11958     accuracy : 0.42681    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89898     accuracy : 0.69596\n",
      "VALID -> loss : 2.32270     accuracy : 0.44562    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88647     accuracy : 0.70037\n",
      "VALID -> loss : 1.60604     accuracy : 0.44856    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.82907     accuracy : 0.71639\n",
      "VALID -> loss : 1.06954     accuracy : 0.62140    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.77374     accuracy : 0.74431\n",
      "VALID -> loss : 1.26650     accuracy : 0.56496    best : 0.95984\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.69191     accuracy : 0.77311\n",
      "VALID -> loss : 0.95784     accuracy : 0.66902    best : 0.95784\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.64651     accuracy : 0.79765\n",
      "VALID -> loss : 0.92163     accuracy : 0.67725    best : 0.92163\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.48655     accuracy : 0.43277\n",
      "VALID -> loss : 1.38424     accuracy : 0.43563    best : 1.38424\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.32058     accuracy : 0.48905\n",
      "VALID -> loss : 1.45805     accuracy : 0.41975    best : 1.38424\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27979     accuracy : 0.52006\n",
      "VALID -> loss : 1.48434     accuracy : 0.41329    best : 1.38424\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24147     accuracy : 0.55239\n",
      "VALID -> loss : 1.22112     accuracy : 0.54733    best : 1.22112\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21096     accuracy : 0.57076\n",
      "VALID -> loss : 1.21627     accuracy : 0.54791    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20732     accuracy : 0.57649\n",
      "VALID -> loss : 1.25262     accuracy : 0.51323    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19741     accuracy : 0.57120\n",
      "VALID -> loss : 1.24039     accuracy : 0.53909    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21381     accuracy : 0.55298\n",
      "VALID -> loss : 1.51759     accuracy : 0.44856    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.19121     accuracy : 0.56841\n",
      "VALID -> loss : 1.24790     accuracy : 0.52616    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18141     accuracy : 0.57179\n",
      "VALID -> loss : 1.83324     accuracy : 0.48560    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.16990     accuracy : 0.57458\n",
      "VALID -> loss : 1.25435     accuracy : 0.52028    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11739     accuracy : 0.59647\n",
      "VALID -> loss : 1.24271     accuracy : 0.54027    best : 1.21627\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08351     accuracy : 0.62101\n",
      "VALID -> loss : 1.11444     accuracy : 0.59788    best : 1.11444\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04567     accuracy : 0.64350\n",
      "VALID -> loss : 1.09934     accuracy : 0.59436    best : 1.09934\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01194     accuracy : 0.65716\n",
      "VALID -> loss : 1.05297     accuracy : 0.62963    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00175     accuracy : 0.65790\n",
      "VALID -> loss : 1.06071     accuracy : 0.63257    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.00684     accuracy : 0.65716\n",
      "VALID -> loss : 1.10142     accuracy : 0.61493    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03800     accuracy : 0.64041\n",
      "VALID -> loss : 1.14750     accuracy : 0.58142    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05393     accuracy : 0.63674\n",
      "VALID -> loss : 1.84681     accuracy : 0.45385    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03874     accuracy : 0.63483\n",
      "VALID -> loss : 1.18220     accuracy : 0.54497    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03735     accuracy : 0.64188\n",
      "VALID -> loss : 1.21619     accuracy : 0.56673    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.01020     accuracy : 0.65628\n",
      "VALID -> loss : 1.16877     accuracy : 0.58495    best : 1.05297\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95972     accuracy : 0.67127\n",
      "VALID -> loss : 1.03395     accuracy : 0.63668    best : 1.03395\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91413     accuracy : 0.69640\n",
      "VALID -> loss : 1.18726     accuracy : 0.56966    best : 1.03395\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.86845     accuracy : 0.71256\n",
      "VALID -> loss : 0.98603     accuracy : 0.65432    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.86479     accuracy : 0.71624\n",
      "VALID -> loss : 0.98993     accuracy : 0.65961    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.87559     accuracy : 0.70816\n",
      "VALID -> loss : 1.07333     accuracy : 0.62140    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89150     accuracy : 0.70301\n",
      "VALID -> loss : 1.22454     accuracy : 0.56085    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93543     accuracy : 0.67906\n",
      "VALID -> loss : 2.17728     accuracy : 0.41152    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94751     accuracy : 0.67392\n",
      "VALID -> loss : 2.20418     accuracy : 0.32040    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93276     accuracy : 0.68479\n",
      "VALID -> loss : 1.16086     accuracy : 0.59730    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90591     accuracy : 0.68699\n",
      "VALID -> loss : 1.13614     accuracy : 0.59259    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.83635     accuracy : 0.71697\n",
      "VALID -> loss : 1.05157     accuracy : 0.62316    best : 0.98603\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.77117     accuracy : 0.74813\n",
      "VALID -> loss : 0.96273     accuracy : 0.65844    best : 0.96273\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.73320     accuracy : 0.76664\n",
      "VALID -> loss : 0.94595     accuracy : 0.67431    best : 0.94595\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.54284     accuracy : 0.41984\n",
      "VALID -> loss : 4.16874     accuracy : 0.39212    best : 4.16874\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.32148     accuracy : 0.49522\n",
      "VALID -> loss : 1.30220     accuracy : 0.48031    best : 1.30220\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.28024     accuracy : 0.51021\n",
      "VALID -> loss : 1.26417     accuracy : 0.49794    best : 1.26417\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.24640     accuracy : 0.53167\n",
      "VALID -> loss : 1.22165     accuracy : 0.52969    best : 1.22165\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22850     accuracy : 0.55121\n",
      "VALID -> loss : 1.21235     accuracy : 0.54086    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22466     accuracy : 0.55077\n",
      "VALID -> loss : 1.21958     accuracy : 0.52675    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22271     accuracy : 0.55371\n",
      "VALID -> loss : 1.29372     accuracy : 0.48148    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22883     accuracy : 0.54901\n",
      "VALID -> loss : 1.33421     accuracy : 0.47266    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22583     accuracy : 0.54416\n",
      "VALID -> loss : 1.25186     accuracy : 0.46972    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21457     accuracy : 0.54930\n",
      "VALID -> loss : 7.29500     accuracy : 0.39447    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18973     accuracy : 0.55253\n",
      "VALID -> loss : 1.74307     accuracy : 0.40447    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.15522     accuracy : 0.57899\n",
      "VALID -> loss : 1.25496     accuracy : 0.52440    best : 1.21235\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11616     accuracy : 0.59515\n",
      "VALID -> loss : 1.15107     accuracy : 0.54850    best : 1.15107\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08109     accuracy : 0.61954\n",
      "VALID -> loss : 1.12109     accuracy : 0.58319    best : 1.12109\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04236     accuracy : 0.63733\n",
      "VALID -> loss : 1.06168     accuracy : 0.61964    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03612     accuracy : 0.64320\n",
      "VALID -> loss : 1.09917     accuracy : 0.59788    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.04737     accuracy : 0.63262\n",
      "VALID -> loss : 1.12809     accuracy : 0.56614    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06054     accuracy : 0.62586\n",
      "VALID -> loss : 1.86086     accuracy : 0.42975    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.11400     accuracy : 0.60206\n",
      "VALID -> loss : 1.39567     accuracy : 0.49794    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.09971     accuracy : 0.60220\n",
      "VALID -> loss : 1.12496     accuracy : 0.59671    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05995     accuracy : 0.62160\n",
      "VALID -> loss : 1.67377     accuracy : 0.42681    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.02751     accuracy : 0.63718\n",
      "VALID -> loss : 1.13484     accuracy : 0.58142    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.99437     accuracy : 0.65452\n",
      "VALID -> loss : 1.09168     accuracy : 0.59436    best : 1.06168\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93118     accuracy : 0.68215\n",
      "VALID -> loss : 0.99123     accuracy : 0.63786    best : 0.99123\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.90742     accuracy : 0.69816\n",
      "VALID -> loss : 0.97682     accuracy : 0.66138    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89264     accuracy : 0.69846\n",
      "VALID -> loss : 1.03381     accuracy : 0.63374    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89937     accuracy : 0.69346\n",
      "VALID -> loss : 2.20862     accuracy : 0.51499    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92426     accuracy : 0.68259\n",
      "VALID -> loss : 0.99143     accuracy : 0.65373    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95827     accuracy : 0.66804\n",
      "VALID -> loss : 1.47534     accuracy : 0.50441    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.98682     accuracy : 0.65878\n",
      "VALID -> loss : 1.42852     accuracy : 0.48148    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.93357     accuracy : 0.67318\n",
      "VALID -> loss : 1.12735     accuracy : 0.57319    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91291     accuracy : 0.68626\n",
      "VALID -> loss : 2.75465     accuracy : 0.40623    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84512     accuracy : 0.71109\n",
      "VALID -> loss : 1.02293     accuracy : 0.62199    best : 0.97682\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.78016     accuracy : 0.73975\n",
      "VALID -> loss : 0.97099     accuracy : 0.66490    best : 0.97099\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.73884     accuracy : 0.75694\n",
      "VALID -> loss : 0.91995     accuracy : 0.68607    best : 0.91995\n",
      "\n",
      "\n",
      "===================== Epoch : 1/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.48930     accuracy : 0.40558\n",
      "VALID -> loss : 1.36491     accuracy : 0.44150    best : 1.36491\n",
      "\n",
      "\n",
      "===================== Epoch : 2/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.31213     accuracy : 0.47715\n",
      "VALID -> loss : 1.38422     accuracy : 0.42504    best : 1.36491\n",
      "\n",
      "\n",
      "===================== Epoch : 3/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.27448     accuracy : 0.49772\n",
      "VALID -> loss : 1.24605     accuracy : 0.52910    best : 1.24605\n",
      "\n",
      "\n",
      "===================== Epoch : 4/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.23768     accuracy : 0.51859\n",
      "VALID -> loss : 1.23504     accuracy : 0.50323    best : 1.23504\n",
      "\n",
      "\n",
      "===================== Epoch : 5/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21891     accuracy : 0.53564\n",
      "VALID -> loss : 1.20423     accuracy : 0.54262    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 6/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20798     accuracy : 0.53461\n",
      "VALID -> loss : 1.21502     accuracy : 0.51499    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 7/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.21093     accuracy : 0.53799\n",
      "VALID -> loss : 1.30826     accuracy : 0.46267    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 8/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22816     accuracy : 0.52520\n",
      "VALID -> loss : 1.64573     accuracy : 0.41329    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 9/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.22073     accuracy : 0.53064\n",
      "VALID -> loss : 1.28609     accuracy : 0.51852    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 10/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.20065     accuracy : 0.53358\n",
      "VALID -> loss : 1.29677     accuracy : 0.52087    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 11/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.18099     accuracy : 0.54798\n",
      "VALID -> loss : 1.25834     accuracy : 0.51558    best : 1.20423\n",
      "\n",
      "\n",
      "===================== Epoch : 12/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.15944     accuracy : 0.56899\n",
      "VALID -> loss : 1.16468     accuracy : 0.57319    best : 1.16468\n",
      "\n",
      "\n",
      "===================== Epoch : 13/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.12568     accuracy : 0.58751\n",
      "VALID -> loss : 1.16284     accuracy : 0.56790    best : 1.16284\n",
      "\n",
      "\n",
      "===================== Epoch : 14/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08392     accuracy : 0.60632\n",
      "VALID -> loss : 1.09006     accuracy : 0.60494    best : 1.09006\n",
      "\n",
      "\n",
      "===================== Epoch : 15/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05211     accuracy : 0.62469\n",
      "VALID -> loss : 1.08358     accuracy : 0.60788    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 16/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05516     accuracy : 0.62204\n",
      "VALID -> loss : 1.10093     accuracy : 0.59024    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 17/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.05751     accuracy : 0.61675\n",
      "VALID -> loss : 1.18734     accuracy : 0.56849    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 18/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.06406     accuracy : 0.61352\n",
      "VALID -> loss : 1.17346     accuracy : 0.55673    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 19/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.10101     accuracy : 0.60382\n",
      "VALID -> loss : 1.37140     accuracy : 0.54674    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 20/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.09713     accuracy : 0.59633\n",
      "VALID -> loss : 1.25016     accuracy : 0.50441    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 21/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.08042     accuracy : 0.61117\n",
      "VALID -> loss : 1.38151     accuracy : 0.53380    best : 1.08358\n",
      "\n",
      "\n",
      "===================== Epoch : 22/35    time : 17s =====================\n",
      "TRAIN -> loss : 1.03382     accuracy : 0.62866\n",
      "VALID -> loss : 1.06393     accuracy : 0.61317    best : 1.06393\n",
      "\n",
      "\n",
      "===================== Epoch : 23/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97483     accuracy : 0.65687\n",
      "VALID -> loss : 0.99670     accuracy : 0.63786    best : 0.99670\n",
      "\n",
      "\n",
      "===================== Epoch : 24/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.92903     accuracy : 0.67774\n",
      "VALID -> loss : 0.98929     accuracy : 0.64374    best : 0.98929\n",
      "\n",
      "\n",
      "===================== Epoch : 25/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89551     accuracy : 0.69611\n",
      "VALID -> loss : 0.95206     accuracy : 0.65256    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 26/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.88815     accuracy : 0.69904\n",
      "VALID -> loss : 0.97880     accuracy : 0.64727    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 27/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.89580     accuracy : 0.69566\n",
      "VALID -> loss : 0.98723     accuracy : 0.63727    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 28/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91096     accuracy : 0.67686\n",
      "VALID -> loss : 1.31486     accuracy : 0.55085    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 29/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.95185     accuracy : 0.66378\n",
      "VALID -> loss : 2.13350     accuracy : 0.45679    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 30/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.97163     accuracy : 0.66187\n",
      "VALID -> loss : 1.79704     accuracy : 0.34509    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 31/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.94801     accuracy : 0.66510\n",
      "VALID -> loss : 2.17790     accuracy : 0.43798    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 32/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.91276     accuracy : 0.68053\n",
      "VALID -> loss : 1.10065     accuracy : 0.60788    best : 0.95206\n",
      "\n",
      "\n",
      "===================== Epoch : 33/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.84798     accuracy : 0.71403\n",
      "VALID -> loss : 0.93705     accuracy : 0.66314    best : 0.93705\n",
      "\n",
      "\n",
      "===================== Epoch : 34/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.77431     accuracy : 0.73872\n",
      "VALID -> loss : 0.91368     accuracy : 0.67372    best : 0.91368\n",
      "\n",
      "\n",
      "===================== Epoch : 35/35    time : 17s =====================\n",
      "TRAIN -> loss : 0.73919     accuracy : 0.75871\n",
      "VALID -> loss : 0.89984     accuracy : 0.68313    best : 0.89984\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for person in range(3):\n",
    "    train_x = np.load('./datasets/train_x_multi.npy')\n",
    "    train_y = np.load('./datasets/train_y_sort.npy')\n",
    "    train_x_min = train_x.min()\n",
    "    train_x_max = train_x.max()\n",
    "\n",
    "\n",
    "    idx = [k+person for k in range(0, len(train_x), 3)][:-1]\n",
    "    train_x=train_x[idx]\n",
    "    train_y=train_y[idx]\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    folds=[]\n",
    "    for train_idx, valid_idx in skf.split(train_x, train_y):\n",
    "        folds.append((train_idx, valid_idx))\n",
    "\n",
    "        \n",
    "    for fold in range(5):\n",
    "        epochs=35\n",
    "        batch_size=128\n",
    "        model_name = f'network-epoch{epochs}-person({person})-fold({fold}).pth'\n",
    "        train_idx, valid_idx = folds[fold]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        train_dataset = VoiceDatasetSimple(X=train_x[train_idx], y=train_y[train_idx], transform=transform, roll=False)\n",
    "        train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "        valid_dataset = VoiceDatasetSimple(X=train_x[valid_idx], y=train_y[valid_idx], transform=transform)\n",
    "        valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "        # model compile\n",
    "        model = Network(16).to(device)\n",
    "        model = nn.DataParallel(model, device_ids=[0,1])\n",
    "        \n",
    "        \n",
    "        # optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr =1e-3)\n",
    "        Q = math.floor(len(train_dataset)/batch_size+1)*epochs/7\n",
    "        lrs = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = Q)\n",
    "        \n",
    "        # loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        best = 9999\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            model.train()\n",
    "            train_loss=0\n",
    "            \n",
    "            train_pred_list=[]\n",
    "            train_true_list=[]\n",
    "            train_log_loss=0\n",
    "            \n",
    "            for X, y in (train_loader):\n",
    "                X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "                y = torch.tensor(y, dtype=torch.float32 , device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(X)\n",
    "                loss = criterion(pred, y.argmax(1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lrs.step()\n",
    "\n",
    "                train_pred_list += F.softmax(pred).argmax(1).detach().cpu().numpy().tolist()\n",
    "                train_true_list += y.argmax(1).detach().cpu().numpy().tolist()\n",
    "                train_loss+=loss.item()\n",
    "                \n",
    "            train_accuracy=accuracy_score(train_true_list, train_pred_list)\n",
    "\n",
    "\n",
    "            #validation set\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_loss=0\n",
    "                valid_log_loss=0\n",
    "                valid_pred_list=[]\n",
    "                valid_true_list=[]\n",
    "                for X, y in (valid_loader):\n",
    "                    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "                    y = torch.tensor(y, dtype=torch.float32 , device=device)\n",
    "\n",
    "                    pred = model(X)\n",
    "                    loss = criterion(pred, y.argmax(1))\n",
    "\n",
    "                    valid_pred_list += F.softmax(pred).argmax(1).detach().cpu().numpy().tolist()\n",
    "                    valid_true_list += y.argmax(1).detach().cpu().numpy().tolist()\n",
    "                    valid_loss+=loss.item()\n",
    "\n",
    "            valid_accuracy=accuracy_score(valid_true_list, valid_pred_list)\n",
    "\n",
    "            \n",
    "            if valid_loss/len(valid_loader) < best:\n",
    "                model_save(model, f'./model/{model_name}')\n",
    "                #model_name = f'network-epoch{epochs}-person({person})-fold({fold}).pth'\n",
    "\n",
    "                best = valid_loss/len(valid_loader)\n",
    "\n",
    "            print(f'===================== Epoch : {epoch+1}/{epochs}    time : {time.time()-start:.0f}s =====================')\n",
    "            \n",
    "            print(f'TRAIN -> loss : {train_loss/len(train_loader):.5f}     accuracy : {train_accuracy:.5f}')\n",
    "            print(f'VALID -> loss : {valid_loss/len(valid_loader):.5f}     accuracy : {valid_accuracy:.5f}    best : {best:.5f}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac58176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ec76e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:08<00:00, 24.98it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 24.65it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.15it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 24.99it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.33it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.29it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 24.76it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.24it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.16it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.36it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 24.83it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.44it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.22it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 24.58it/s]\n",
      "100%|██████████| 204/204 [00:08<00:00, 25.34it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load('./datasets/test_x_multi.npy')\n",
    "\n",
    "test_dataset = VoiceDatasetSimple(X=X_test, y=None, transform=transform, inference=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=30, shuffle=False, num_workers=8)\n",
    "\n",
    "result=0\n",
    "for person in range(3):\n",
    "    for fold in range(5):\n",
    "        with torch.no_grad():\n",
    "            weights = torch.load(f'./model/network-epoch{epochs}-person({person})-fold({fold}).pth')\n",
    "            model.load_state_dict(weights['model'])\n",
    "            model.eval()\n",
    "            preds = []\n",
    "            \n",
    "            for X in tqdm(test_loader):\n",
    "                X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "                pred = F.softmax(model(X)).detach().cpu().numpy().tolist()\n",
    "                preds+=pred\n",
    "        preds = np.array(preds)\n",
    "        result+=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e030ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  africa  australia  canada  england  hongkong  us\n",
       "0        1       0          0       0        0         0   0\n",
       "1        2       0          0       0        0         0   0\n",
       "2        3       0          0       0        0         0   0\n",
       "3        4       0          0       0        0         0   0\n",
       "4        5       0          0       0        0         0   0\n",
       "...    ...     ...        ...     ...      ...       ...  ..\n",
       "6095  6096       0          0       0        0         0   0\n",
       "6096  6097       0          0       0        0         0   0\n",
       "6097  6098       0          0       0        0         0   0\n",
       "6098  6099       0          0       0        0         0   0\n",
       "6099  6100       0          0       0        0         0   0\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14d2e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31334412  0.73361432  0.63588197  8.346238    0.31911697  4.65180464]\n",
      " [ 0.71494263  1.50730311  1.33333371  6.34792918  0.29333935  4.80315232]\n",
      " [ 0.04651754  0.16694858  0.37291009  1.72701741  0.19022985 12.49637653]\n",
      " ...\n",
      " [ 0.79062995  0.52689598  0.71029282  4.35570826  0.60575328  8.01071981]\n",
      " [ 1.32944301  0.70592121  0.80506993  4.18037177  1.33073388  6.64846009]\n",
      " [ 0.39235762  0.77945921  1.03747175  3.85502675  0.96437984  7.97130488]]\n",
      "(6100, 6)\n",
      "[[0.02088961 0.04890762 0.04239213 0.55641587 0.02127446 0.31012031]\n",
      " [0.04766284 0.10048687 0.08888891 0.42319528 0.01955596 0.32021015]\n",
      " [0.00310117 0.01112991 0.02486067 0.11513449 0.01268199 0.83309177]\n",
      " ...\n",
      " [0.05270866 0.0351264  0.04735285 0.29038055 0.04038355 0.53404799]\n",
      " [0.08862953 0.04706141 0.05367133 0.27869145 0.08871559 0.44323067]\n",
      " [0.02615717 0.05196395 0.06916478 0.25700178 0.06429199 0.53142033]]\n",
      "(6100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(result.shape)\n",
    "print(result/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30aed83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission.iloc[:,1:] = result/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8aafd2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020890</td>\n",
       "      <td>0.048908</td>\n",
       "      <td>0.042392</td>\n",
       "      <td>0.556416</td>\n",
       "      <td>0.021274</td>\n",
       "      <td>0.310120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047663</td>\n",
       "      <td>0.100487</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.423195</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.320210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.115134</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>0.833092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.064851</td>\n",
       "      <td>0.056437</td>\n",
       "      <td>0.062335</td>\n",
       "      <td>0.233133</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.547031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.256728</td>\n",
       "      <td>0.013920</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.130895</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.517218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.026397</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.797693</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.133387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0.205598</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>0.023535</td>\n",
       "      <td>0.153146</td>\n",
       "      <td>0.061605</td>\n",
       "      <td>0.539907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0.052709</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.047353</td>\n",
       "      <td>0.290381</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>0.534048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0.088630</td>\n",
       "      <td>0.047061</td>\n",
       "      <td>0.053671</td>\n",
       "      <td>0.278691</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.443231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>0.051964</td>\n",
       "      <td>0.069165</td>\n",
       "      <td>0.257002</td>\n",
       "      <td>0.064292</td>\n",
       "      <td>0.531420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    africa  australia    canada   england  hongkong        us\n",
       "0        1  0.020890   0.048908  0.042392  0.556416  0.021274  0.310120\n",
       "1        2  0.047663   0.100487  0.088889  0.423195  0.019556  0.320210\n",
       "2        3  0.003101   0.011130  0.024861  0.115134  0.012682  0.833092\n",
       "3        4  0.064851   0.056437  0.062335  0.233133  0.036213  0.547031\n",
       "4        5  0.256728   0.013920  0.021993  0.130895  0.059247  0.517218\n",
       "...    ...       ...        ...       ...       ...       ...       ...\n",
       "6095  6096  0.015142   0.026397  0.016701  0.797693  0.010681  0.133387\n",
       "6096  6097  0.205598   0.016208  0.023535  0.153146  0.061605  0.539907\n",
       "6097  6098  0.052709   0.035126  0.047353  0.290381  0.040384  0.534048\n",
       "6098  6099  0.088630   0.047061  0.053671  0.278691  0.088716  0.443231\n",
       "6099  6100  0.026157   0.051964  0.069165  0.257002  0.064292  0.531420\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
